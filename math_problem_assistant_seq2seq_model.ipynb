{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\" \n",
    "    Encoder for the sequence-to-sequence math problem assistant model using an LSTM. \n",
    "    Converts a sequence of token indices into a hidden representation \n",
    "    that will be used by the decoder for sequence generation.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        \"\"\"\n",
    "        Initializes the Encoder module.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): The size of the input vocabulary.\n",
    "            hidden_size (int): The number of hidden units in the LSTM.\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        # Embedding layer converts token indices into dense vectors for better representation.\n",
    "        # The embeddings refer to vector representations of words or tokens used as input to the model.\n",
    "        # Instead of feeding raw word indices (which don’t capture meaning), feedingembeddings allows\n",
    "        # the LSTM to learn meaningful semantic relationships between words.\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        # LSTM layer processes embedded input sequences to generate hidden states\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        \"\"\"\n",
    "        Forward pass through the encoder.\n",
    "\n",
    "        Args:\n",
    "            input_seq (Tensor): Tensor containing token indices for a batch of input sentences.\n",
    "\n",
    "        Returns:\n",
    "            outputs (Tensor): Encoder outputs at each time step.\n",
    "            hidden (Tensor): Final hidden state of the LSTM.\n",
    "            cell (Tensor): Final cell state of the LSTM.\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(input_seq)            # Convert input tokens into embeddings \n",
    "        outputs, (hidden, cell) = self.lstm(embedded)   # Process embeddings through LSTM\n",
    "        return outputs, (hidden, cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \"\"\" \n",
    "    Attention model for the sequence-to-sequence math problem assistant\n",
    "    which implements a 'Bahdanau attention' mechanism. This allows the model\n",
    "    to dynamically compute attention scores based on the decoder's hidden\n",
    "    state and the encoder's outputs, allowing the model to focus on relevant\n",
    "    parts of the input sequence at each decoding step.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size):\n",
    "        \"\"\"\n",
    "        Initializes the attention mechanism.\n",
    "\n",
    "        Args:\n",
    "            hidden_size (int): The size of the hidden state of the LSTM.\n",
    "        \"\"\"\n",
    "        super(Attention, self).__init__()\n",
    "        # Learnable linear transformation to compute alignment scores\n",
    "        self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        # Learnable parameter to compute weighted attention scores\n",
    "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        \"\"\"\n",
    "        Computes attention weights using Bahdanau's additive attention method.\n",
    "\n",
    "        Args:\n",
    "            hidden (Tensor): Decoder hidden state at the current time step.\n",
    "            encoder_outputs (Tensor): Encoder outputs at all time steps.\n",
    "\n",
    "        Returns:\n",
    "            attention_weights (Tensor): Softmax-normalized attention scores.\n",
    "        \"\"\"\n",
    "        seq_len = encoder_outputs.size(1)\n",
    "        # Expand the hidden state across sequence length to match encoder outputs\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, seq_len, 1)\n",
    "        # Compute energy scores (alignment) using a feed-forward layer\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        # Transpose energy tensor for matrix multiplication with attention parameter\n",
    "        energy = energy.permute(0, 2, 1)\n",
    "        # Expand attention parameter across batch size\n",
    "        v = self.v.repeat(encoder_outputs.size(0), 1).unsqueeze(1)\n",
    "        # Compute attention weights using learned vector `v`\n",
    "        attention_weights = torch.bmm(v, energy).squeeze(1)\n",
    "        # Apply softmax to normalize scores across sequence length\n",
    "        return torch.softmax(attention_weights, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\" \n",
    "    Encoder for the sequence-to-sequence math problem assistant model using an\n",
    "    LSTM with Bahdanau attention. The decoder generates output tokens one by one\n",
    "    while dynamically focusing  on relevant parts of the encoder’s outputs using\n",
    "    the attention mechanism.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_size, hidden_size):\n",
    "        \"\"\"\n",
    "        Initializes the Decoder module.\n",
    "\n",
    "        Args:\n",
    "            output_size (int): The size of the output vocabulary.\n",
    "            hidden_size (int): The number of hidden units in the LSTM.\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        # Embedding layer converts token indices into dense vectors\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        # LSTM layer processes embeddings and maintains hidden state across timesteps\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        # Linear layer maps concatenated attention context & LSTM output to vocab space\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "        # Attention mechanism for dynamic focus on encoder outputs\n",
    "        self.attention = Attention(hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden, cell, encoder_outputs):\n",
    "        \"\"\"\n",
    "        Forward pass for the decoder.\n",
    "\n",
    "        Args:\n",
    "            input (Tensor): Current token input to the decoder.\n",
    "            hidden (Tensor): Previous hidden state from the LSTM.\n",
    "            cell (Tensor): Previous cell state from the LSTM.\n",
    "            encoder_outputs (Tensor): Encoder outputs from all timesteps.\n",
    "\n",
    "        Returns:\n",
    "            output (Tensor): Predicted token probabilities.\n",
    "            hidden (Tensor): Updated hidden state.\n",
    "            cell (Tensor): Updated cell state.\n",
    "            attention_weights (Tensor): Attention scores for each encoder timestep.\n",
    "        \"\"\"\n",
    "        # Expand input dimensions to match expected input shape for embedding\n",
    "        input = input.unsqueeze(1)  \n",
    "        # Convert token indices into dense embeddings\n",
    "        embedded = self.embedding(input)\n",
    "        # Forward pass through LSTM to generate new hidden and cell states\n",
    "        lstm_output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        # Compute attention weights using the current hidden state and encoder outputs\n",
    "        attention_weights = self.attention(hidden[-1], encoder_outputs)\n",
    "        # Apply attention: generate weighted sum of encoder outputs\n",
    "        context = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs)\n",
    "        # Flatten tensors for the fully connected layer\n",
    "        lstm_output = lstm_output.squeeze(1)\n",
    "        context = context.squeeze(1)\n",
    "        # Generate token probabilities using concatenated LSTM output and attention context\n",
    "        output = self.fc(torch.cat((lstm_output, context), dim=1))\n",
    "\n",
    "        return output, hidden, cell, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Basic Tokenization and Vocabulary Setup\n",
    "First, create a vocabulary and tokenize the input sentence (e.g., \"two plus four\" etc). To keep things extremely simple we'll manually establish a 'word-to-index' vocabulary whihc offers a simple map from word to tokensized integer value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and vocab setup\n",
    "# Create a vocabulary mapping words to indices\n",
    "word_to_index = {\"<SOS>\": 0, \"<EOS>\": 1, \"<PAD>\": 2, \"two\": 3, \"plus\": 4, \"four\": 5, \"equals\": 6, \"six\": 7, \"three\": 8, \"minus\": 9, \"one\": 10}\n",
    "index_to_word = {v: k for k, v in word_to_index.items()}  # Reverse mapping for decoding\n",
    "\n",
    "# Example input and target sequences\n",
    "input_sentence = \"two plus four\"\n",
    "target_sentence = \"equals six\"\n",
    "\n",
    "# Test Tokenized input and targets\n",
    "input_tokens = [word_to_index[word] for word in input_sentence.split()]\n",
    "target_tokens = [word_to_index[\"<SOS>\"]] + [word_to_index[word] for word in target_sentence.split()] + [word_to_index[\"<EOS>\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the math problem dataset from the tokenzied data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicMathWordProblemDataset(Dataset):\n",
    "    def __init__(self, input_sentences, target_sentences, word_to_index):\n",
    "        self.input_data = [[word_to_index[word] for word in sentence.split()] for sentence in input_sentences]\n",
    "        self.target_data = [[word_to_index[\"<SOS>\"]] +\n",
    "                            [word_to_index[word] for word in sentence.split()] +\n",
    "                            [word_to_index[\"<EOS>\"]] for sentence in target_sentences]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.input_data[idx], dtype=torch.long), torch.tensor(self.target_data[idx], dtype=torch.long)\n",
    "\n",
    "# Example data\n",
    "input_sentences = [\"two plus four\"]\n",
    "target_sentences = [\"equals six\"]\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = BasicMathWordProblemDataset(input_sentences, target_sentences, word_to_index)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instantiate the encoder and decoder\n",
    "input_size = len(word_to_index)  # Total vocabulary size\n",
    "output_size = len(word_to_index)  # Vocabulary size\n",
    "hidden_size = 128\n",
    "\n",
    "encoder = Encoder(input_size, hidden_size).to(device)\n",
    "decoder = Decoder(output_size, hidden_size).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word_to_index[\"<PAD>\"])  # Ignore padding tokens\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)\n",
    "attention_matrix = []  # Store attention weights for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish the training regime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, encoder_save_name, decoder_save_name):\n",
    "    \"\"\"\n",
    "    Trains the sequence-to-sequence model using an encoder-decoder architecture.\n",
    "\n",
    "    Args:\n",
    "        num_epochs (int): Number of training epochs.\n",
    "        encoder_save_name (str): File name for saving the trained encoder model.\n",
    "        decoder_save_name (str): File name for saving the trained decoder model.\n",
    "    \"\"\"\n",
    "    for epoch in range(num_epochs):\n",
    "        for input_seq, target_seq in dataloader:\n",
    "            # Move data to GPU if available, else keep on CPU\n",
    "            input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n",
    "\n",
    "            # Reset gradients before each batch\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "\n",
    "            # **ENCODER FORWARD PASS**\n",
    "            # Processes the input sequence and generates context for the decoder\n",
    "            encoder_outputs, (hidden, cell) = encoder(input_seq)\n",
    "\n",
    "            # **DECODER INITIALIZATION**\n",
    "            # The first input to the decoder is always the <SOS> token\n",
    "            decoder_input = torch.tensor([word_to_index[\"<SOS>\"]] * input_seq.size(0), device=device)\n",
    "            decoder_hidden, decoder_cell = hidden, cell\n",
    "\n",
    "            # Compute actual target sequence lengths (excluding padding)\n",
    "            target_lengths = (target_seq != word_to_index[\"<PAD>\"]).sum(dim=1)\n",
    "            max_target_length = target_lengths.max().item()  # Maximum sequence length in batch\n",
    "\n",
    "            loss = 0  # Track loss per batch\n",
    "            \n",
    "            # **ITERATE OVER TARGET SEQUENCE (Adaptive length)**\n",
    "            for t in range(max_target_length):\n",
    "                # Check if sequences are still active (haven't reached <EOS>)\n",
    "                still_active = t < target_lengths\n",
    "                if not still_active.any():  # If all sequences are finished, stop decoding\n",
    "                    break\n",
    "\n",
    "                # **DECODER FORWARD PASS**\n",
    "                output, decoder_hidden, decoder_cell, attention_weights = decoder(\n",
    "                    decoder_input, decoder_hidden, decoder_cell, encoder_outputs\n",
    "                )\n",
    "\n",
    "                # Compute masked loss (only valid tokens contribute to loss)\n",
    "                loss += (criterion(output, target_seq[:, t]) * still_active.float()).sum() / still_active.sum()\n",
    "\n",
    "                # Apply teacher forcing: Use actual target token as next input\n",
    "                decoder_input = target_seq[:, t]  \n",
    "\n",
    "            # **BACKPROPAGATION & OPTIMIZATION**\n",
    "            loss.backward()  # Compute gradients\n",
    "            encoder_optimizer.step()  # Update encoder weights\n",
    "            decoder_optimizer.step()  # Update decoder weights\n",
    "\n",
    "        # Print epoch loss for tracking progress\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "        attention_matrix.append(attention_weights.cpu().detach().numpy())  # Convert to NumPy for plotting\n",
    "    \n",
    "    # **SAVE TRAINED MODELS**\n",
    "    torch.save(encoder.state_dict(), f\"{encoder_save_name}.pth\")\n",
    "    torch.save(decoder.state_dict(), f\"{decoder_save_name}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100  # Define the number of epochs\n",
    "train(num_epochs, \"basic_math_problem_encoder\", \"basic_math_problem_decoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(encoder, decoder, input_sentence):\n",
    "    # Set the models to evaluation mode\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    # Tokenize the input sentence\n",
    "    input_tokens = [word_to_index[word] for word in input_sentence.split()]\n",
    "    input_seq = torch.tensor(input_tokens, dtype=torch.long).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # generate the output sequence\n",
    "    # Forward pass through the encoder\n",
    "    encoder_outputs, (hidden, cell) = encoder(input_seq)\n",
    "\n",
    "    # Initialize the decoder\n",
    "    decoder_input = torch.tensor([word_to_index[\"<SOS>\"]], dtype=torch.long)  # Start-of-Sequence token\n",
    "    decoder_hidden = hidden\n",
    "    decoder_cell = cell\n",
    "\n",
    "    # Generate output sequence\n",
    "    output_sequence = []\n",
    "    target_length = 100  # Maximum output sequence length\n",
    "\n",
    "    for _ in range(target_length):\n",
    "        output, decoder_hidden, decoder_cell, _ = decoder(\n",
    "            decoder_input, decoder_hidden, decoder_cell, encoder_outputs\n",
    "        )\n",
    "        predicted_token = output.argmax(1).item()  # Get token with the highest probability\n",
    "        if predicted_token == word_to_index[\"<EOS>\"]:  # Stop at End-of-Sequence token\n",
    "            break\n",
    "        output_sequence.append(predicted_token)\n",
    "        decoder_input = torch.tensor([predicted_token], dtype=torch.long)\n",
    "\n",
    "    print(\"Word to index: \", word_to_index)\n",
    "    print(\"Input tokens: \", input_tokens)\n",
    "    print(\"Tokenized output sentence: \", output_sequence)\n",
    "\n",
    "    # Convert tokens back to words\n",
    "    output_sentence = \" \".join([index_to_word[token] for token in output_sequence])\n",
    "    print(\"Output Sentence:\", output_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained model\n",
    "input_size = len(word_to_index)  # Same as during training\n",
    "output_size = len(word_to_index)\n",
    "hidden_size = 128  # Same as during training\n",
    "\n",
    "encoder = Encoder(input_size, hidden_size)\n",
    "decoder = Decoder(output_size, hidden_size)\n",
    "\n",
    "# Load the trained weights\n",
    "encoder.load_state_dict(torch.load(\"basic_math_problem_encoder.pth\"))\n",
    "decoder.load_state_dict(torch.load(\"basic_math_problem_decoder.pth\"))\n",
    "\n",
    "input_sentence = \"two plus four\"\n",
    "\n",
    "test(encoder, decoder, input_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish a more complex dataset and train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish a baseline vocabulary and tokenization capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define special tokens\n",
    "word_to_index = {\"<SOS>\": 0, \"<EOS>\": 1, \"<PAD>\": 2}  # establish only the baseline tokens this time\n",
    " \n",
    "# Function to tokenize a sentence and update mapping dynamically\n",
    "def tokenize(sentence, word_to_index):\n",
    "    tokens = []\n",
    "    for word in sentence.lower().split():\n",
    "        if word not in word_to_index:\n",
    "            word_to_index[word] = len(word_to_index)  # Assign index to new words\n",
    "        tokens.append(word_to_index[word])\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CSV dataset from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from CSV\n",
    "def load_sequences_from_csv(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    return df[\"Problem\"].tolist(), df[\"Solution\"].tolist()\n",
    "\n",
    "csv_file = \"simple_math_problems_addition_only.csv\"\n",
    "input_sentences, target_sentences = load_sequences_from_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize input and target sentences and convert into tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize input and target sentences\n",
    "input_data = [tokenize(sentence, word_to_index) for sentence in input_sentences]\n",
    "target_data = [[word_to_index[\"<SOS>\"]] + tokenize(sentence, word_to_index) + [word_to_index[\"<EOS>\"]]\n",
    "               for sentence in target_sentences]\n",
    "\n",
    "index_to_word = {v: k for k, v in word_to_index.items()}\n",
    "\n",
    "# Convert tokenized sentences into tensors\n",
    "input_tensors = [torch.tensor(seq) for seq in input_data]\n",
    "target_tensors = [torch.tensor(seq) for seq in target_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the math problem dataset from the tokenzied data, including padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply dynamic padding\n",
    "input_padded = pad_sequence(input_tensors, batch_first=True, padding_value=word_to_index[\"<PAD>\"])\n",
    "target_padded = pad_sequence(target_tensors, batch_first=True, padding_value=word_to_index[\"<PAD>\"])\n",
    "\n",
    "class DynamicMathWordProblemDataset(Dataset):\n",
    "    def __init__(self, input_padded, target_padded):\n",
    "        self.input_data = input_padded\n",
    "        self.target_data = target_padded\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_data[idx], self.target_data[idx]\n",
    "\n",
    "dataset = DynamicMathWordProblemDataset(input_padded, target_padded)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_size = len(word_to_index)  # Vocabulary size\n",
    "output_size = len(word_to_index)\n",
    "hidden_size = 256\n",
    "\n",
    "encoder = Encoder(input_size, hidden_size).to(device)\n",
    "decoder = Decoder(output_size, hidden_size).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word_to_index[\"<PAD>\"])\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.0005)#0.001)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.0005)#0.001)\n",
    "\n",
    "num_epochs = 100  # Define the number of epochs\n",
    "train(num_epochs, \"addition_only_math_problem_encoder\", \"addition_only_math_problem_decoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the revised model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained model\n",
    "input_size = len(word_to_index)  # Same as during training\n",
    "output_size = len(word_to_index)\n",
    "hidden_size = 256  # Same as during training\n",
    "\n",
    "encoder = Encoder(input_size, hidden_size)\n",
    "decoder = Decoder(output_size, hidden_size)\n",
    "\n",
    "# Load the trained weights\n",
    "encoder.load_state_dict(torch.load(\"addition_only_math_problem_encoder.pth\"))\n",
    "decoder.load_state_dict(torch.load(\"addition_only_math_problem_decoder.pth\"))\n",
    "\n",
    "input_sentence = \"twenty plus fifty nine\" #zero point eight six\n",
    "\n",
    "test(encoder, decoder, input_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the trained model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the attention matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function for hyperparameter tuning\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters to be tuned\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 128, 512)  # Hidden layer size\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)  # LR (log-scaled search)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)  # Dropout rate\n",
    "    \n",
    "    # Define encoder-decoder with suggested hyperparameters\n",
    "    encoder = Encoder(input_size, hidden_size).to(device)\n",
    "    decoder = Decoder(output_size, hidden_size).to(device)\n",
    "\n",
    "    # Apply dropout in LSTM layers\n",
    "    encoder.lstm.dropout = dropout_rate\n",
    "    decoder.lstm.dropout = dropout_rate\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=word_to_index[\"<PAD>\"])\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Run one epoch to evaluate hyperparameter performance\n",
    "    total_loss = 0\n",
    "    for input_seq, target_seq in dataloader:\n",
    "        input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, (hidden, cell) = encoder(input_seq)\n",
    "        decoder_input = torch.tensor([word_to_index[\"<SOS>\"]] * input_seq.size(0), device=device)\n",
    "        decoder_hidden, decoder_cell = hidden, cell\n",
    "\n",
    "        loss = 0\n",
    "        for t in range(target_seq.size(1)):\n",
    "            output, decoder_hidden, decoder_cell, _ = decoder(decoder_input, decoder_hidden, decoder_cell, encoder_outputs)\n",
    "            loss += criterion(output, target_seq[:, t])\n",
    "            decoder_input = target_seq[:, t]  # Teacher forcing\n",
    "        \n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)  # Optuna minimizes this loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform optimum hyperparameter search\n",
    "\n",
    "\n",
    "Best hyperparameters: {'hidden_size': 283, 'learning_rate': 0.004869044905756817, 'dropout_rate': 0.28901830138217327}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")  # Minimize loss\n",
    "study.optimize(objective, n_trials=30)  # Run 30 optimization trials\n",
    "\n",
    "# Print best hyperparameter combination\n",
    "print(\"Best hyperparameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Output: [\"J'aime\", 'mécanismes', 'attention', '.']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# when we send test input generate an attention map\n",
    "\n",
    "test_input = [\"I\", \"love\", \"attention\", \"mechanisms\", \".\"]  # Example test input\n",
    "ground_truth_output = [\"J'aime\", \"les\", \"mécanismes\", \"d'attention\", \".\"]  # Example output\n",
    "\n",
    "# Simulated model prediction and attention weights\n",
    "predicted_output = [\"J'aime\", \"mécanismes\", \"attention\", \".\"]  # Example prediction\n",
    "attention_weights = np.random.rand(len(predicted_output), len(test_input))  # Replace with actual weights\n",
    "\n",
    "# Print predicted output for reference\n",
    "print(\"Predicted Output:\", predicted_output)\n",
    "\n",
    "\n",
    "###############################################################################################################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_attention(input_tokens, output_tokens, attention_matrix):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(attention_matrix, cmap=\"viridis\", interpolation=\"nearest\")\n",
    "    \n",
    "    # Add labels for tokens\n",
    "    plt.xticks(ticks=np.arange(len(input_tokens)), labels=input_tokens, rotation=45, ha=\"right\")\n",
    "    plt.yticks(ticks=np.arange(len(output_tokens)), labels=output_tokens)\n",
    "    \n",
    "    # Add axis labels\n",
    "    plt.xlabel(\"Input Tokens\")\n",
    "    plt.ylabel(\"Predicted Output Tokens\")\n",
    "    plt.title(\"Attention Heatmap\")\n",
    "    \n",
    "    # Add a color bar\n",
    "    plt.colorbar(label=\"Attention Weight\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the plot function\n",
    "input_tokens = test_input\n",
    "output_tokens = predicted_output\n",
    "plot_attention(input_tokens, output_tokens, attention_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
