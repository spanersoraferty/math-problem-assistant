{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Local\\Temp\\ipykernel_12736\\2013348885.py\", line 3, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\__init__.py\", line 39, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\compat\\__init__.py\", line 27, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\compat\\pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.3 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.3 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Local\\Temp\\ipykernel_12736\\2013348885.py\", line 3, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\api.py\", line 9, in <module>\n",
      "    from pandas.core.dtypes.dtypes import (\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\dtypes\\dtypes.py\", line 24, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.3 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.3 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Local\\Temp\\ipykernel_12736\\2013348885.py\", line 3, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 50, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\ops\\__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\ops\\array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\computation\\expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\computation\\check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\numexpr\\__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Local\\Temp\\ipykernel_12736\\2013348885.py\", line 3, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 64, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\masked.py\", line 60, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"C:\\Users\\Spencer\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"c:\\Users\\Spencer\\anaconda3\\Lib\\site-packages\\bottleneck\\__init__.py\", line 7, in <module>\n",
      "    from .move import (move_argmax, move_argmin, move_max, move_mean, move_median,\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.3 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.3 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from num2words import num2words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        embedded = self.embedding(input_seq)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        return outputs, (hidden, cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        seq_len = encoder_outputs.size(1)\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, seq_len, 1)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        energy = energy.permute(0, 2, 1)\n",
    "        v = self.v.repeat(encoder_outputs.size(0), 1).unsqueeze(1)\n",
    "        attention_weights = torch.bmm(v, energy).squeeze(1)\n",
    "        return torch.softmax(attention_weights, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "        self.attention = Attention(hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden, cell, encoder_outputs):\n",
    "        input = input.unsqueeze(1)\n",
    "        embedded = self.embedding(input)\n",
    "        lstm_output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        attention_weights = self.attention(hidden[-1], encoder_outputs)\n",
    "        context = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs)\n",
    "        lstm_output = lstm_output.squeeze(1)\n",
    "        context = context.squeeze(1)\n",
    "        output = self.fc(torch.cat((lstm_output, context), dim=1))\n",
    "        return output, hidden, cell, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Tokenization and Vocabulary Setup\n",
    "First, create a vocabulary and tokenize the input sentence (e.g., \"two plus four\" etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and vocab setup\n",
    "# Create a vocabulary mapping words to indices\n",
    "word_to_index = {\"<SOS>\": 0, \"<EOS>\": 1, \"<PAD>\": 2, \"two\": 3, \"plus\": 4, \"four\": 5, \"equals\": 6, \"six\": 7, \"three\": 8, \"minus\": 9, \"one\": 10}\n",
    "index_to_word = {v: k for k, v in word_to_index.items()}  # Reverse mapping for decoding\n",
    "\n",
    "# Example input and target sequences\n",
    "input_sentence = \"two plus four\"\n",
    "target_sentence = \"equals six\"\n",
    "\n",
    "# Tokenize the sentences\n",
    "input_tokens = [word_to_index[word] for word in input_sentence.split()]\n",
    "target_tokens = [word_to_index[\"<SOS>\"]] + [word_to_index[word] for word in target_sentence.split()] + [word_to_index[\"<EOS>\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the math problem dataset from the tokenzied data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathWordProblemDataset(Dataset):\n",
    "    def __init__(self, input_sentences, target_sentences, word_to_index):\n",
    "        self.input_data = [[word_to_index[word] for word in sentence.split()] for sentence in input_sentences]\n",
    "        self.target_data = [[word_to_index[\"<SOS>\"]] + [word_to_index[word] for word in sentence.split()] + [word_to_index[\"<EOS>\"]] for sentence in target_sentences]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.input_data[idx], dtype=torch.long), torch.tensor(self.target_data[idx], dtype=torch.long)\n",
    "\n",
    "# Example data\n",
    "input_sentences = [\"two plus four\"]\n",
    "target_sentences = [\"equals six\"]\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = MathWordProblemDataset(input_sentences, target_sentences, word_to_index)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "target_length = len(target_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 2.4103245735168457\n",
      "Epoch 2/100, Loss: 2.2287492752075195\n",
      "Epoch 3/100, Loss: 2.0566091537475586\n",
      "Epoch 4/100, Loss: 1.889136552810669\n",
      "Epoch 5/100, Loss: 1.7241028547286987\n",
      "Epoch 6/100, Loss: 1.5615434646606445\n",
      "Epoch 7/100, Loss: 1.4053171873092651\n",
      "Epoch 8/100, Loss: 1.2593914270401\n",
      "Epoch 9/100, Loss: 1.1260111331939697\n",
      "Epoch 10/100, Loss: 1.0062053203582764\n",
      "Epoch 11/100, Loss: 0.8999430537223816\n",
      "Epoch 12/100, Loss: 0.806317925453186\n",
      "Epoch 13/100, Loss: 0.7239124774932861\n",
      "Epoch 14/100, Loss: 0.6511362195014954\n",
      "Epoch 15/100, Loss: 0.5864681601524353\n",
      "Epoch 16/100, Loss: 0.5286604166030884\n",
      "Epoch 17/100, Loss: 0.4768688976764679\n",
      "Epoch 18/100, Loss: 0.4305743873119354\n",
      "Epoch 19/100, Loss: 0.38930758833885193\n",
      "Epoch 20/100, Loss: 0.35242703557014465\n",
      "Epoch 21/100, Loss: 0.3191846013069153\n",
      "Epoch 22/100, Loss: 0.2889707088470459\n",
      "Epoch 23/100, Loss: 0.261469304561615\n",
      "Epoch 24/100, Loss: 0.2365783154964447\n",
      "Epoch 25/100, Loss: 0.2141919881105423\n",
      "Epoch 26/100, Loss: 0.1940980851650238\n",
      "Epoch 27/100, Loss: 0.17606857419013977\n",
      "Epoch 28/100, Loss: 0.15992914140224457\n",
      "Epoch 29/100, Loss: 0.1455361545085907\n",
      "Epoch 30/100, Loss: 0.13272932171821594\n",
      "Epoch 31/100, Loss: 0.12132173776626587\n",
      "Epoch 32/100, Loss: 0.1111237108707428\n",
      "Epoch 33/100, Loss: 0.10196679085493088\n",
      "Epoch 34/100, Loss: 0.09370952844619751\n",
      "Epoch 35/100, Loss: 0.08624168485403061\n",
      "Epoch 36/100, Loss: 0.07948252558708191\n",
      "Epoch 37/100, Loss: 0.07337038964033127\n",
      "Epoch 38/100, Loss: 0.06785053759813309\n",
      "Epoch 39/100, Loss: 0.06286792457103729\n",
      "Epoch 40/100, Loss: 0.058369480073451996\n",
      "Epoch 41/100, Loss: 0.05430445820093155\n",
      "Epoch 42/100, Loss: 0.0506252758204937\n",
      "Epoch 43/100, Loss: 0.04728671908378601\n",
      "Epoch 44/100, Loss: 0.044248223304748535\n",
      "Epoch 45/100, Loss: 0.041476018726825714\n",
      "Epoch 46/100, Loss: 0.038942914456129074\n",
      "Epoch 47/100, Loss: 0.03662671893835068\n",
      "Epoch 48/100, Loss: 0.03450814262032509\n",
      "Epoch 49/100, Loss: 0.03257019817829132\n",
      "Epoch 50/100, Loss: 0.03079644963145256\n",
      "Epoch 51/100, Loss: 0.0291727464646101\n",
      "Epoch 52/100, Loss: 0.02768564410507679\n",
      "Epoch 53/100, Loss: 0.026323115453124046\n",
      "Epoch 54/100, Loss: 0.025073597207665443\n",
      "Epoch 55/100, Loss: 0.023926792666316032\n",
      "Epoch 56/100, Loss: 0.022872677072882652\n",
      "Epoch 57/100, Loss: 0.021902263164520264\n",
      "Epoch 58/100, Loss: 0.021007150411605835\n",
      "Epoch 59/100, Loss: 0.020179811865091324\n",
      "Epoch 60/100, Loss: 0.019413409754633904\n",
      "Epoch 61/100, Loss: 0.018701916560530663\n",
      "Epoch 62/100, Loss: 0.018039841204881668\n",
      "Epoch 63/100, Loss: 0.017422480508685112\n",
      "Epoch 64/100, Loss: 0.0168455820530653\n",
      "Epoch 65/100, Loss: 0.016305454075336456\n",
      "Epoch 66/100, Loss: 0.015798445791006088\n",
      "Epoch 67/100, Loss: 0.015321830287575722\n",
      "Epoch 68/100, Loss: 0.014872732572257519\n",
      "Epoch 69/100, Loss: 0.014448905363678932\n",
      "Epoch 70/100, Loss: 0.014048127457499504\n",
      "Epoch 71/100, Loss: 0.013668524101376534\n",
      "Epoch 72/100, Loss: 0.013308420777320862\n",
      "Epoch 73/100, Loss: 0.012966226786375046\n",
      "Epoch 74/100, Loss: 0.01264073234051466\n",
      "Epoch 75/100, Loss: 0.01233060285449028\n",
      "Epoch 76/100, Loss: 0.012034857645630836\n",
      "Epoch 77/100, Loss: 0.011752365157008171\n",
      "Epoch 78/100, Loss: 0.011482402682304382\n",
      "Epoch 79/100, Loss: 0.011224071495234966\n",
      "Epoch 80/100, Loss: 0.010976763442158699\n",
      "Epoch 81/100, Loss: 0.010739634744822979\n",
      "Epoch 82/100, Loss: 0.010512075386941433\n",
      "Epoch 83/100, Loss: 0.010293621569871902\n",
      "Epoch 84/100, Loss: 0.01008366048336029\n",
      "Epoch 85/100, Loss: 0.009881551377475262\n",
      "Epoch 86/100, Loss: 0.009687121026217937\n",
      "Epoch 87/100, Loss: 0.00949978455901146\n",
      "Epoch 88/100, Loss: 0.009319133125245571\n",
      "Epoch 89/100, Loss: 0.009144876152276993\n",
      "Epoch 90/100, Loss: 0.008976574055850506\n",
      "Epoch 91/100, Loss: 0.00881408341228962\n",
      "Epoch 92/100, Loss: 0.008656934835016727\n",
      "Epoch 93/100, Loss: 0.008504864759743214\n",
      "Epoch 94/100, Loss: 0.008357669226825237\n",
      "Epoch 95/100, Loss: 0.008215174078941345\n",
      "Epoch 96/100, Loss: 0.008076995611190796\n",
      "Epoch 97/100, Loss: 0.007942931726574898\n",
      "Epoch 98/100, Loss: 0.00781283713877201\n",
      "Epoch 99/100, Loss: 0.007686621975153685\n",
      "Epoch 100/100, Loss: 0.007563876453787088\n"
     ]
    }
   ],
   "source": [
    "# Define the device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instantiate the encoder and decoder\n",
    "input_size = len(word_to_index)  # Total vocabulary size\n",
    "output_size = len(word_to_index)  # Vocabulary size\n",
    "hidden_size = 128\n",
    "encoder = Encoder(input_size, hidden_size).to(device)\n",
    "decoder = Decoder(output_size, hidden_size).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word_to_index[\"<PAD>\"])  # Ignore padding tokens\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100  # Define the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    for input_seq, target_seq in dataloader:\n",
    "        # Move data to device (CPU or GPU)\n",
    "        input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        # Encoder forward pass\n",
    "        encoder_outputs, (hidden, cell) = encoder(input_seq)\n",
    "\n",
    "        # Decoder initialization\n",
    "        decoder_input = torch.tensor([word_to_index[\"<SOS>\"]]*input_seq.size(0), device=device)\n",
    "        decoder_hidden, decoder_cell = hidden, cell\n",
    "\n",
    "        # Iterate over the target sequence\n",
    "        loss = 0\n",
    "        for t in range(target_seq.size(1)):\n",
    "            output, decoder_hidden, decoder_cell, attention_weights = decoder(\n",
    "                decoder_input, decoder_hidden, decoder_cell, encoder_outputs\n",
    "            )\n",
    "            loss += criterion(output, target_seq[:, t])\n",
    "            decoder_input = target_seq[:, t]  # Teacher forcing\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item() / target_seq.size(1)}\")\n",
    "\n",
    "\n",
    "torch.save(encoder.state_dict(), \"encoder.pth\")\n",
    "torch.save(decoder.state_dict(), \"decoder.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Sentence: <SOS> equals six\n"
     ]
    }
   ],
   "source": [
    "# load the trained model\n",
    "input_size = len(word_to_index)  # Same as during training\n",
    "output_size = len(word_to_index)\n",
    "hidden_size = 128  # Same as during training\n",
    "\n",
    "encoder = Encoder(input_size, hidden_size)\n",
    "decoder = Decoder(output_size, hidden_size)\n",
    "\n",
    "# Load the trained weights\n",
    "encoder.load_state_dict(torch.load(\"encoder.pth\"))\n",
    "decoder.load_state_dict(torch.load(\"decoder.pth\"))\n",
    "\n",
    "# Set the models to evaluation mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Tokenize the input sentence\n",
    "new_input_sentence = \"two plus four\"\n",
    "input_tokens = [word_to_index[word] for word in new_input_sentence.split()]\n",
    "input_seq = torch.tensor(input_tokens, dtype=torch.long).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# generate the output sequence\n",
    "# Forward pass through the encoder\n",
    "encoder_outputs, (hidden, cell) = encoder(input_seq)\n",
    "\n",
    "# Initialize the decoder\n",
    "decoder_input = torch.tensor([word_to_index[\"<SOS>\"]], dtype=torch.long)  # Start-of-Sequence token\n",
    "decoder_hidden = hidden\n",
    "decoder_cell = cell\n",
    "\n",
    "# Generate output sequence\n",
    "output_sequence = []\n",
    "target_length = 10  # Maximum output sequence length\n",
    "\n",
    "for _ in range(target_length):\n",
    "    output, decoder_hidden, decoder_cell, _ = decoder(\n",
    "        decoder_input, decoder_hidden, decoder_cell, encoder_outputs\n",
    "    )\n",
    "    predicted_token = output.argmax(1).item()  # Get token with the highest probability\n",
    "    if predicted_token == word_to_index[\"<EOS>\"]:  # Stop at End-of-Sequence token\n",
    "        break\n",
    "    output_sequence.append(predicted_token)\n",
    "    decoder_input = torch.tensor([predicted_token], dtype=torch.long)\n",
    "\n",
    "# Convert tokens back to words\n",
    "output_sentence = \" \".join([index_to_word[token] for token in output_sequence])\n",
    "print(\"Output Sentence:\", output_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to math_problems.csv\n"
     ]
    }
   ],
   "source": [
    "class MathProblemGenerator:\n",
    "    def __init__(self, num_samples=1000, output_file=\"math_problems.csv\"):\n",
    "        \"\"\"Initialize the math problem generator.\"\"\"\n",
    "        self.num_samples = num_samples\n",
    "        self.output_file = output_file\n",
    "        self.operations = [\n",
    "            (\"plus\", lambda x, y: x + y),\n",
    "            (\"minus\", lambda x, y: x - y),\n",
    "            (\"times\", lambda x, y: x * y),\n",
    "            (\"divided by\", lambda x, y: round(x / y, 2) if y != 0 else None)\n",
    "        ]\n",
    "\n",
    "    def generate_problem(self):\n",
    "        \"\"\"Generate a single math problem and its solution.\"\"\"\n",
    "        num1 = random.randint(1, 100)\n",
    "        num2 = random.randint(1, 100)\n",
    "        operation, func = random.choice(self.operations)\n",
    "\n",
    "        if operation == \"divided by\" and num2 == 0:\n",
    "            num2 = random.randint(1, 100)\n",
    "\n",
    "        result = func(num1, num2)\n",
    "        result_word = num2words(result).replace(\"-\", \" \").replace(\",\", \"\") if result is not None else \"undefined\"\n",
    "        question = f\"{num2words(num1)} {operation} {num2words(num2)}\"\n",
    "        question = question.replace(\"-\", \" \")\n",
    "        answer = result_word\n",
    "\n",
    "        return question, answer\n",
    "\n",
    "    def generate_dataset(self):\n",
    "        \"\"\"Generate a dataset of word math problems.\"\"\"\n",
    "        data = [self.generate_problem() for _ in range(self.num_samples)]\n",
    "        df = pd.DataFrame(data, columns=[\"Problem\", \"Solution\"])\n",
    "        return df\n",
    "\n",
    "    def save_dataset(self):\n",
    "        \"\"\"Save the dataset to a CSV file.\"\"\"\n",
    "        df = self.generate_dataset()\n",
    "        df.to_csv(self.output_file, index=False)\n",
    "        print(f\"Dataset saved to {self.output_file}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    generator = MathProblemGenerator(num_samples=500)\n",
    "    generator.save_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build with padding for variable lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 8.435881614685059\n",
      "Epoch 2/100, Loss: 9.399575233459473\n",
      "Epoch 3/100, Loss: 8.125503540039062\n",
      "Epoch 4/100, Loss: 5.971968650817871\n",
      "Epoch 5/100, Loss: 5.773557662963867\n",
      "Epoch 6/100, Loss: 8.668047904968262\n",
      "Epoch 7/100, Loss: 4.308411598205566\n",
      "Epoch 8/100, Loss: 7.212804794311523\n",
      "Epoch 9/100, Loss: 6.785924434661865\n",
      "Epoch 10/100, Loss: 4.278359413146973\n",
      "Epoch 11/100, Loss: 2.962790012359619\n",
      "Epoch 12/100, Loss: 4.216248512268066\n",
      "Epoch 13/100, Loss: 2.2711069583892822\n",
      "Epoch 14/100, Loss: 2.6026406288146973\n",
      "Epoch 15/100, Loss: 4.96159029006958\n",
      "Epoch 16/100, Loss: 1.2994388341903687\n",
      "Epoch 17/100, Loss: 1.5031147003173828\n",
      "Epoch 18/100, Loss: 0.9496104717254639\n",
      "Epoch 19/100, Loss: 0.7755101919174194\n",
      "Epoch 20/100, Loss: 0.7613001465797424\n",
      "Epoch 21/100, Loss: 0.6068370342254639\n",
      "Epoch 22/100, Loss: 0.3680368661880493\n",
      "Epoch 23/100, Loss: 0.2974961996078491\n",
      "Epoch 24/100, Loss: 0.6025023460388184\n",
      "Epoch 25/100, Loss: 1.3211833238601685\n",
      "Epoch 26/100, Loss: 0.3709910809993744\n",
      "Epoch 27/100, Loss: 1.604391098022461\n",
      "Epoch 28/100, Loss: 0.21580883860588074\n",
      "Epoch 29/100, Loss: 0.08298336714506149\n",
      "Epoch 30/100, Loss: 0.0561082549393177\n",
      "Epoch 31/100, Loss: 0.11061518639326096\n",
      "Epoch 32/100, Loss: 0.05465434491634369\n",
      "Epoch 33/100, Loss: 0.07162556797266006\n",
      "Epoch 34/100, Loss: 0.05047868937253952\n",
      "Epoch 35/100, Loss: 0.052297983318567276\n",
      "Epoch 36/100, Loss: 0.07499472796916962\n",
      "Epoch 37/100, Loss: 0.019183922559022903\n",
      "Epoch 38/100, Loss: 0.022051816806197166\n",
      "Epoch 39/100, Loss: 0.023682976141572\n",
      "Epoch 40/100, Loss: 0.013959454372525215\n",
      "Epoch 41/100, Loss: 0.014067795127630234\n",
      "Epoch 42/100, Loss: 0.008597324602305889\n",
      "Epoch 43/100, Loss: 0.015721574425697327\n",
      "Epoch 44/100, Loss: 0.010078605264425278\n",
      "Epoch 45/100, Loss: 0.00715505238622427\n",
      "Epoch 46/100, Loss: 0.005602105520665646\n",
      "Epoch 47/100, Loss: 0.005954153370112181\n",
      "Epoch 48/100, Loss: 0.004778203554451466\n",
      "Epoch 49/100, Loss: 1.1443580389022827\n",
      "Epoch 50/100, Loss: 0.18619698286056519\n",
      "Epoch 51/100, Loss: 0.40836256742477417\n",
      "Epoch 52/100, Loss: 0.7407870888710022\n",
      "Epoch 53/100, Loss: 0.04358776658773422\n",
      "Epoch 54/100, Loss: 0.07527414709329605\n",
      "Epoch 55/100, Loss: 0.05859977751970291\n",
      "Epoch 56/100, Loss: 0.022585494443774223\n",
      "Epoch 57/100, Loss: 0.032774418592453\n",
      "Epoch 58/100, Loss: 0.04512502998113632\n",
      "Epoch 59/100, Loss: 0.029697218909859657\n",
      "Epoch 60/100, Loss: 0.015230745077133179\n",
      "Epoch 61/100, Loss: 0.018995964899659157\n",
      "Epoch 62/100, Loss: 0.027447357773780823\n",
      "Epoch 63/100, Loss: 0.011860487051308155\n",
      "Epoch 64/100, Loss: 0.013663997873663902\n",
      "Epoch 65/100, Loss: 0.010538432747125626\n",
      "Epoch 66/100, Loss: 0.015527031384408474\n",
      "Epoch 67/100, Loss: 0.007996929809451103\n",
      "Epoch 68/100, Loss: 0.00713552488014102\n",
      "Epoch 69/100, Loss: 0.007076762616634369\n",
      "Epoch 70/100, Loss: 0.006382373161613941\n",
      "Epoch 71/100, Loss: 0.006424878723919392\n",
      "Epoch 72/100, Loss: 0.008083569817245007\n",
      "Epoch 73/100, Loss: 0.007293398957699537\n",
      "Epoch 74/100, Loss: 0.006366049870848656\n",
      "Epoch 75/100, Loss: 0.0043014055117964745\n",
      "Epoch 76/100, Loss: 0.007719225715845823\n",
      "Epoch 77/100, Loss: 0.001951117068529129\n",
      "Epoch 78/100, Loss: 0.0033298046328127384\n",
      "Epoch 79/100, Loss: 0.0040630982257425785\n",
      "Epoch 80/100, Loss: 0.002578373998403549\n",
      "Epoch 81/100, Loss: 0.004148558713495731\n",
      "Epoch 82/100, Loss: 0.0017497638473287225\n",
      "Epoch 83/100, Loss: 0.0032843099907040596\n",
      "Epoch 84/100, Loss: 0.0012648747069761157\n",
      "Epoch 85/100, Loss: 0.001905807526782155\n",
      "Epoch 86/100, Loss: 0.0007679325644858181\n",
      "Epoch 87/100, Loss: 0.001924020703881979\n",
      "Epoch 88/100, Loss: 0.0006791834020987153\n",
      "Epoch 89/100, Loss: 0.0006019448628649116\n",
      "Epoch 90/100, Loss: 0.0007036860333755612\n",
      "Epoch 91/100, Loss: 0.0004300034779589623\n",
      "Epoch 92/100, Loss: 0.0004337156715337187\n",
      "Epoch 93/100, Loss: 0.0004144622653257102\n",
      "Epoch 94/100, Loss: 0.00037013052497059107\n",
      "Epoch 95/100, Loss: 0.0002869824238587171\n",
      "Epoch 96/100, Loss: 0.0003133835271000862\n",
      "Epoch 97/100, Loss: 0.00020908366423100233\n",
      "Epoch 98/100, Loss: 4.314200401306152\n",
      "Epoch 99/100, Loss: 22.177270889282227\n",
      "Epoch 100/100, Loss: 0.10866093635559082\n"
     ]
    }
   ],
   "source": [
    "# Define special tokens\n",
    "word_to_index = {\"<SOS>\": 0, \"<EOS>\": 1, \"<PAD>\": 2}  \n",
    " \n",
    "\n",
    "# Function to tokenize a sentence and update mapping dynamically\n",
    "def tokenize(sentence, word_to_index):\n",
    "    tokens = []\n",
    "    for word in sentence.lower().split():\n",
    "        if word not in word_to_index:\n",
    "            word_to_index[word] = len(word_to_index)  # Assign index to new words\n",
    "        tokens.append(word_to_index[word])\n",
    "    return tokens\n",
    "\n",
    "# Load dataset from CSV\n",
    "def load_sequences_from_csv(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    return df[\"Problem\"].tolist(), df[\"Solution\"].tolist()\n",
    "\n",
    "csv_file = \"math_problems.csv\"\n",
    "input_sentences, target_sentences = load_sequences_from_csv(csv_file)\n",
    "\n",
    "# Tokenize input and target sentences\n",
    "input_data = [tokenize(sentence, word_to_index) for sentence in input_sentences]\n",
    "target_data = [[word_to_index[\"<SOS>\"]] + tokenize(sentence, word_to_index) + [word_to_index[\"<EOS>\"]]\n",
    "               for sentence in target_sentences]\n",
    "\n",
    "index_to_word = {v: k for k, v in word_to_index.items()}\n",
    "\n",
    "# Convert tokenized sentences into tensors\n",
    "input_tensors = [torch.tensor(seq) for seq in input_data]\n",
    "target_tensors = [torch.tensor(seq) for seq in target_data]\n",
    "\n",
    "# Apply dynamic padding\n",
    "input_padded = pad_sequence(input_tensors, batch_first=True, padding_value=word_to_index[\"<PAD>\"])\n",
    "target_padded = pad_sequence(target_tensors, batch_first=True, padding_value=word_to_index[\"<PAD>\"])\n",
    "\n",
    "class MathWordProblemDataset(Dataset):\n",
    "    def __init__(self, input_padded, target_padded):\n",
    "        self.input_data = input_padded\n",
    "        self.target_data = target_padded\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_data[idx], self.target_data[idx]\n",
    "\n",
    "dataset = MathWordProblemDataset(input_padded, target_padded)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_size = len(word_to_index)  # Vocabulary size\n",
    "output_size = len(word_to_index)\n",
    "hidden_size = 128\n",
    "\n",
    "encoder = Encoder(input_size, hidden_size).to(device)\n",
    "decoder = Decoder(output_size, hidden_size).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word_to_index[\"<PAD>\"])\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for input_seq, target_seq in dataloader:\n",
    "        input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, (hidden, cell) = encoder(input_seq)\n",
    "\n",
    "        decoder_input = torch.tensor([word_to_index[\"<SOS>\"]] * input_seq.size(0), device=device)\n",
    "        decoder_hidden, decoder_cell = hidden, cell\n",
    "\n",
    "        target_lengths = (target_seq != word_to_index[\"<PAD>\"]).sum(dim=1)\n",
    "\n",
    "        loss = 0\n",
    "        max_target_length = target_lengths.max().item()\n",
    "\n",
    "        for t in range(max_target_length):\n",
    "            still_active = t < target_lengths\n",
    "            if not still_active.any():\n",
    "                break\n",
    "\n",
    "            output, decoder_hidden, decoder_cell, _ = decoder(\n",
    "                decoder_input, decoder_hidden, decoder_cell, encoder_outputs\n",
    "            )\n",
    "            loss += (criterion(output, target_seq[:, t]) * still_active.float()).sum() / still_active.sum()\n",
    "\n",
    "            decoder_input = target_seq[:, t]  # Teacher forcing\n",
    "\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "torch.save(encoder.state_dict(), \"encoderX.pth\")\n",
    "torch.save(decoder.state_dict(), \"decoderX.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the son bitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<SOS>': 0, '<EOS>': 1, '<PAD>': 2, 'thirty': 3, 'six': 4, 'minus': 5, 'eighty': 6, 'three': 7, 'eight': 8, 'seventy': 9, 'times': 10, 'twenty': 11, 'five': 12, 'ninety': 13, 'seven': 14, 'plus': 15, 'one': 16, 'forty': 17, 'sixty': 18, 'divided': 19, 'by': 20, 'two': 21, 'nineteen': 22, 'nine': 23, 'eleven': 24, 'four': 25, 'eighteen': 26, 'fifty': 27, 'ten': 28, 'twelve': 29, 'seventeen': 30, 'hundred': 31, 'thirteen': 32, 'sixteen': 33, 'fifteen': 34, 'fourteen': 35, 'thousand': 36, 'and': 37, 'point': 38, 'zero': 39}\n",
      "[6, 7, 19, 20, 13, 14]\n",
      "[0, 16, 38, 23, 14]\n",
      "Output Sentence: <SOS> one point nine seven\n"
     ]
    }
   ],
   "source": [
    "# load the trained model\n",
    "input_size = len(word_to_index)  # Same as during training\n",
    "output_size = len(word_to_index)\n",
    "hidden_size = 128  # Same as during training\n",
    "\n",
    "encoder = Encoder(input_size, hidden_size)\n",
    "decoder = Decoder(output_size, hidden_size)\n",
    "\n",
    "# Load the trained weights\n",
    "encoder.load_state_dict(torch.load(\"encoderX.pth\"))\n",
    "decoder.load_state_dict(torch.load(\"decoderX.pth\"))\n",
    "\n",
    "# Set the models to evaluation mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Tokenize the input sentence\n",
    "new_input_sentence = \"eighty three divided by ninety seven\" #zero point eight six\n",
    "input_tokens = [word_to_index[word] for word in new_input_sentence.split()]\n",
    "input_seq = torch.tensor(input_tokens, dtype=torch.long).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "\n",
    "# generate the output sequence\n",
    "# Forward pass through the encoder\n",
    "encoder_outputs, (hidden, cell) = encoder(input_seq)\n",
    "\n",
    "# Initialize the decoder\n",
    "decoder_input = torch.tensor([word_to_index[\"<SOS>\"]], dtype=torch.long)  # Start-of-Sequence token\n",
    "decoder_hidden = hidden\n",
    "decoder_cell = cell\n",
    "\n",
    "# Generate output sequence\n",
    "output_sequence = []\n",
    "target_length = 100  # Maximum output sequence length\n",
    "\n",
    "for _ in range(target_length):\n",
    "    output, decoder_hidden, decoder_cell, _ = decoder(\n",
    "        decoder_input, decoder_hidden, decoder_cell, encoder_outputs\n",
    "    )\n",
    "    predicted_token = output.argmax(1).item()  # Get token with the highest probability\n",
    "    if predicted_token == word_to_index[\"<EOS>\"]:  # Stop at End-of-Sequence token\n",
    "        break\n",
    "    output_sequence.append(predicted_token)\n",
    "    decoder_input = torch.tensor([predicted_token], dtype=torch.long)\n",
    "\n",
    "print(word_to_index)\n",
    "\n",
    "print(input_tokens)\n",
    "\n",
    "print(output_sequence)\n",
    "\n",
    "\n",
    "# Convert tokens back to words\n",
    "output_sentence = \" \".join([index_to_word[token] for token in output_sequence])\n",
    "print(\"Output Sentence:\", output_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
