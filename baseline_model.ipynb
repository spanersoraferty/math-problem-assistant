{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        embedded = self.embedding(input_seq)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        return outputs, (hidden, cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        seq_len = encoder_outputs.size(1)\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, seq_len, 1)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        energy = energy.permute(0, 2, 1)\n",
    "        v = self.v.repeat(encoder_outputs.size(0), 1).unsqueeze(1)\n",
    "        attention_weights = torch.bmm(v, energy).squeeze(1)\n",
    "        return torch.softmax(attention_weights, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "        self.attention = Attention(hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden, cell, encoder_outputs):\n",
    "        input = input.unsqueeze(1)\n",
    "        embedded = self.embedding(input)\n",
    "        lstm_output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        attention_weights = self.attention(hidden[-1], encoder_outputs)\n",
    "        context = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs)\n",
    "        lstm_output = lstm_output.squeeze(1)\n",
    "        context = context.squeeze(1)\n",
    "        output = self.fc(torch.cat((lstm_output, context), dim=1))\n",
    "        return output, hidden, cell, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and Vocabulary Setup\n",
    "First, create a vocabulary and tokenize the input sentence (e.g., \"two plus four\" etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and vocab setup\n",
    "# Create a vocabulary mapping words to indices\n",
    "word_to_index = {\"<SOS>\": 0, \"<EOS>\": 1, \"<PAD>\": 2, \"two\": 3, \"plus\": 4, \"four\": 5, \"equals\": 6, \"six\": 7, \"three\": 8, \"minus\": 9, \"one\": 10}\n",
    "index_to_word = {v: k for k, v in word_to_index.items()}  # Reverse mapping for decoding\n",
    "\n",
    "# Example input and target sequences\n",
    "input_sentence = \"two plus four\"\n",
    "target_sentence = \"equals six\"\n",
    "\n",
    "# Tokenize the sentences\n",
    "input_tokens = [word_to_index[word] for word in input_sentence.split()]\n",
    "target_tokens = [word_to_index[\"<SOS>\"]] + [word_to_index[word] for word in target_sentence.split()] + [word_to_index[\"<EOS>\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the math problem dataset from the tokenzied data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathWordProblemDataset(Dataset):\n",
    "    def __init__(self, input_sentences, target_sentences, word_to_index):\n",
    "        self.input_data = [[word_to_index[word] for word in sentence.split()] for sentence in input_sentences]\n",
    "        self.target_data = [[word_to_index[\"<SOS>\"]] + [word_to_index[word] for word in sentence.split()] + [word_to_index[\"<EOS>\"]] for sentence in target_sentences]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.input_data[idx], dtype=torch.long), torch.tensor(self.target_data[idx], dtype=torch.long)\n",
    "\n",
    "# Example data\n",
    "input_sentences = [\"two plus four\"]\n",
    "target_sentences = [\"equals six\"]\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = MathWordProblemDataset(input_sentences, target_sentences, word_to_index)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "target_length = len(target_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 2.438589572906494\n",
      "Epoch 2/100, Loss: 2.271918296813965\n",
      "Epoch 3/100, Loss: 2.1174967288970947\n",
      "Epoch 4/100, Loss: 1.9624028205871582\n",
      "Epoch 5/100, Loss: 1.803347110748291\n",
      "Epoch 6/100, Loss: 1.6440132856369019\n",
      "Epoch 7/100, Loss: 1.4897698163986206\n",
      "Epoch 8/100, Loss: 1.343505859375\n",
      "Epoch 9/100, Loss: 1.2075986862182617\n",
      "Epoch 10/100, Loss: 1.084038496017456\n",
      "Epoch 11/100, Loss: 0.9736529588699341\n",
      "Epoch 12/100, Loss: 0.8760510087013245\n",
      "Epoch 13/100, Loss: 0.7900800704956055\n",
      "Epoch 14/100, Loss: 0.7143363952636719\n",
      "Epoch 15/100, Loss: 0.6474581360816956\n",
      "Epoch 16/100, Loss: 0.5882113575935364\n",
      "Epoch 17/100, Loss: 0.5355003476142883\n",
      "Epoch 18/100, Loss: 0.4883628189563751\n",
      "Epoch 19/100, Loss: 0.4459781050682068\n",
      "Epoch 20/100, Loss: 0.40768325328826904\n",
      "Epoch 21/100, Loss: 0.3729633390903473\n",
      "Epoch 22/100, Loss: 0.3414159119129181\n",
      "Epoch 23/100, Loss: 0.31273677945137024\n",
      "Epoch 24/100, Loss: 0.2867087423801422\n",
      "Epoch 25/100, Loss: 0.2630557715892792\n",
      "Epoch 26/100, Loss: 0.24134668707847595\n",
      "Epoch 27/100, Loss: 0.22122980654239655\n",
      "Epoch 28/100, Loss: 0.20253334939479828\n",
      "Epoch 29/100, Loss: 0.18522608280181885\n",
      "Epoch 30/100, Loss: 0.1693495512008667\n",
      "Epoch 31/100, Loss: 0.15490680932998657\n",
      "Epoch 32/100, Loss: 0.1417950838804245\n",
      "Epoch 33/100, Loss: 0.1298457831144333\n",
      "Epoch 34/100, Loss: 0.11890624463558197\n",
      "Epoch 35/100, Loss: 0.1088743507862091\n",
      "Epoch 36/100, Loss: 0.09968753904104233\n",
      "Epoch 37/100, Loss: 0.0913008600473404\n",
      "Epoch 38/100, Loss: 0.08367536962032318\n",
      "Epoch 39/100, Loss: 0.0767691433429718\n",
      "Epoch 40/100, Loss: 0.07053292542695999\n",
      "Epoch 41/100, Loss: 0.06490900367498398\n",
      "Epoch 42/100, Loss: 0.05983477830886841\n",
      "Epoch 43/100, Loss: 0.05524923652410507\n",
      "Epoch 44/100, Loss: 0.0510978177189827\n",
      "Epoch 45/100, Loss: 0.047334518283605576\n",
      "Epoch 46/100, Loss: 0.043921034783124924\n",
      "Epoch 47/100, Loss: 0.04082471504807472\n",
      "Epoch 48/100, Loss: 0.038017354905605316\n",
      "Epoch 49/100, Loss: 0.03547333553433418\n",
      "Epoch 50/100, Loss: 0.03316972777247429\n",
      "Epoch 51/100, Loss: 0.031085707247257233\n",
      "Epoch 52/100, Loss: 0.029201697558164597\n",
      "Epoch 53/100, Loss: 0.02749856747686863\n",
      "Epoch 54/100, Loss: 0.025957833975553513\n",
      "Epoch 55/100, Loss: 0.02456159144639969\n",
      "Epoch 56/100, Loss: 0.02329319342970848\n",
      "Epoch 57/100, Loss: 0.022137993946671486\n",
      "Epoch 58/100, Loss: 0.02108289860188961\n",
      "Epoch 59/100, Loss: 0.020116668194532394\n",
      "Epoch 60/100, Loss: 0.01922929473221302\n",
      "Epoch 61/100, Loss: 0.01841253973543644\n",
      "Epoch 62/100, Loss: 0.017658885568380356\n",
      "Epoch 63/100, Loss: 0.01696193963289261\n",
      "Epoch 64/100, Loss: 0.016316086053848267\n",
      "Epoch 65/100, Loss: 0.015716325491666794\n",
      "Epoch 66/100, Loss: 0.015158186666667461\n",
      "Epoch 67/100, Loss: 0.014637892134487629\n",
      "Epoch 68/100, Loss: 0.01415181253105402\n",
      "Epoch 69/100, Loss: 0.013697132468223572\n",
      "Epoch 70/100, Loss: 0.013270853087306023\n",
      "Epoch 71/100, Loss: 0.012870663776993752\n",
      "Epoch 72/100, Loss: 0.012494398280978203\n",
      "Epoch 73/100, Loss: 0.01213994063436985\n",
      "Epoch 74/100, Loss: 0.011805642396211624\n",
      "Epoch 75/100, Loss: 0.01148976106196642\n",
      "Epoch 76/100, Loss: 0.0111910505220294\n",
      "Epoch 77/100, Loss: 0.010907996445894241\n",
      "Epoch 78/100, Loss: 0.010639643296599388\n",
      "Epoch 79/100, Loss: 0.010384942404925823\n",
      "Epoch 80/100, Loss: 0.010142489336431026\n",
      "Epoch 81/100, Loss: 0.009911765344440937\n",
      "Epoch 82/100, Loss: 0.009691894054412842\n",
      "Epoch 83/100, Loss: 0.009482057765126228\n",
      "Epoch 84/100, Loss: 0.009281701408326626\n",
      "Epoch 85/100, Loss: 0.009090006351470947\n",
      "Epoch 86/100, Loss: 0.00890650600194931\n",
      "Epoch 87/100, Loss: 0.00873064249753952\n",
      "Epoch 88/100, Loss: 0.008561920374631882\n",
      "Epoch 89/100, Loss: 0.008399812504649162\n",
      "Epoch 90/100, Loss: 0.008243993856012821\n",
      "Epoch 91/100, Loss: 0.008094029501080513\n",
      "Epoch 92/100, Loss: 0.007949534803628922\n",
      "Epoch 93/100, Loss: 0.00781024806201458\n",
      "Epoch 94/100, Loss: 0.007675786502659321\n",
      "Epoch 95/100, Loss: 0.0075459470972418785\n",
      "Epoch 96/100, Loss: 0.007420404814183712\n",
      "Epoch 97/100, Loss: 0.007298956159502268\n",
      "Epoch 98/100, Loss: 0.007181423716247082\n",
      "Epoch 99/100, Loss: 0.007067397236824036\n",
      "Epoch 100/100, Loss: 0.006956994067877531\n"
     ]
    }
   ],
   "source": [
    "# Define the device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instantiate the encoder and decoder\n",
    "input_size = len(word_to_index)  # Total vocabulary size\n",
    "output_size = len(word_to_index)  # Vocabulary size\n",
    "hidden_size = 128\n",
    "encoder = Encoder(input_size, hidden_size).to(device)\n",
    "decoder = Decoder(output_size, hidden_size).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word_to_index[\"<PAD>\"])  # Ignore padding tokens\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100  # Define the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    for input_seq, target_seq in dataloader:\n",
    "        # Move data to device (CPU or GPU)\n",
    "        input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        # Encoder forward pass\n",
    "        encoder_outputs, (hidden, cell) = encoder(input_seq)\n",
    "\n",
    "        # Decoder initialization\n",
    "        decoder_input = torch.tensor([word_to_index[\"<SOS>\"]]*input_seq.size(0), device=device)\n",
    "        decoder_hidden, decoder_cell = hidden, cell\n",
    "\n",
    "        # Iterate over the target sequence\n",
    "        loss = 0\n",
    "        for t in range(target_seq.size(1)):\n",
    "            output, decoder_hidden, decoder_cell, attention_weights = decoder(\n",
    "                decoder_input, decoder_hidden, decoder_cell, encoder_outputs\n",
    "            )\n",
    "            loss += criterion(output, target_seq[:, t])\n",
    "            decoder_input = target_seq[:, t]  # Teacher forcing\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item() / target_seq.size(1)}\")\n",
    "\n",
    "\n",
    "torch.save(encoder.state_dict(), \"encoder.pth\")\n",
    "torch.save(decoder.state_dict(), \"decoder.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Sentence: <SOS> equals six\n"
     ]
    }
   ],
   "source": [
    "# load the trained model\n",
    "input_size = len(word_to_index)  # Same as during training\n",
    "output_size = len(word_to_index)\n",
    "hidden_size = 128  # Same as during training\n",
    "\n",
    "encoder = Encoder(input_size, hidden_size)\n",
    "decoder = Decoder(output_size, hidden_size)\n",
    "\n",
    "# Load the trained weights\n",
    "encoder.load_state_dict(torch.load(\"encoder.pth\"))\n",
    "decoder.load_state_dict(torch.load(\"decoder.pth\"))\n",
    "\n",
    "# Set the models to evaluation mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Tokenize the input sentence\n",
    "new_input_sentence = \"two plus four\"\n",
    "input_tokens = [word_to_index[word] for word in new_input_sentence.split()]\n",
    "input_seq = torch.tensor(input_tokens, dtype=torch.long).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# generate the output sequence\n",
    "# Forward pass through the encoder\n",
    "encoder_outputs, (hidden, cell) = encoder(input_seq)\n",
    "\n",
    "# Initialize the decoder\n",
    "decoder_input = torch.tensor([word_to_index[\"<SOS>\"]], dtype=torch.long)  # Start-of-Sequence token\n",
    "decoder_hidden = hidden\n",
    "decoder_cell = cell\n",
    "\n",
    "# Generate output sequence\n",
    "output_sequence = []\n",
    "target_length = 10  # Maximum output sequence length\n",
    "\n",
    "for _ in range(target_length):\n",
    "    output, decoder_hidden, decoder_cell, _ = decoder(\n",
    "        decoder_input, decoder_hidden, decoder_cell, encoder_outputs\n",
    "    )\n",
    "    predicted_token = output.argmax(1).item()  # Get token with the highest probability\n",
    "    if predicted_token == word_to_index[\"<EOS>\"]:  # Stop at End-of-Sequence token\n",
    "        break\n",
    "    output_sequence.append(predicted_token)\n",
    "    decoder_input = torch.tensor([predicted_token], dtype=torch.long)\n",
    "\n",
    "# Convert tokens back to words\n",
    "output_sentence = \" \".join([index_to_word[token] for token in output_sequence])\n",
    "print(\"Output Sentence:\", output_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build with padding for variable lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 4.455081462860107\n",
      "Epoch 2/100, Loss: 3.914167642593384\n",
      "Epoch 3/100, Loss: 1.9789586067199707\n",
      "Epoch 4/100, Loss: 1.2735586166381836\n",
      "Epoch 5/100, Loss: 2.5654962062835693\n",
      "Epoch 6/100, Loss: 4.185352802276611\n",
      "Epoch 7/100, Loss: 0.7171554565429688\n",
      "Epoch 8/100, Loss: 0.5447468757629395\n",
      "Epoch 9/100, Loss: 3.604170799255371\n",
      "Epoch 10/100, Loss: 6.16872501373291\n",
      "Epoch 11/100, Loss: 0.6679847240447998\n",
      "Epoch 12/100, Loss: 0.09699192643165588\n",
      "Epoch 13/100, Loss: 0.08766615390777588\n",
      "Epoch 14/100, Loss: 1.9832141399383545\n",
      "Epoch 15/100, Loss: 0.25376373529434204\n",
      "Epoch 16/100, Loss: 2.5221049785614014\n",
      "Epoch 17/100, Loss: 0.13194917142391205\n",
      "Epoch 18/100, Loss: 0.06081368774175644\n",
      "Epoch 19/100, Loss: 1.653520107269287\n",
      "Epoch 20/100, Loss: 2.3549647331237793\n",
      "Epoch 21/100, Loss: 2.0650980472564697\n",
      "Epoch 22/100, Loss: 0.027934523299336433\n",
      "Epoch 23/100, Loss: 0.17629414796829224\n",
      "Epoch 24/100, Loss: 1.1658247709274292\n",
      "Epoch 25/100, Loss: 2.563602924346924\n",
      "Epoch 26/100, Loss: 0.20028197765350342\n",
      "Epoch 27/100, Loss: 0.021099936217069626\n",
      "Epoch 28/100, Loss: 1.1130398511886597\n",
      "Epoch 29/100, Loss: 1.2638249397277832\n",
      "Epoch 30/100, Loss: 0.3851069509983063\n",
      "Epoch 31/100, Loss: 1.6925089359283447\n",
      "Epoch 32/100, Loss: 0.9268109202384949\n",
      "Epoch 33/100, Loss: 0.06320565193891525\n",
      "Epoch 34/100, Loss: 0.1229424998164177\n",
      "Epoch 35/100, Loss: 0.9126980900764465\n",
      "Epoch 36/100, Loss: 5.360853672027588\n",
      "Epoch 37/100, Loss: 1.508242130279541\n",
      "Epoch 38/100, Loss: 3.046151876449585\n",
      "Epoch 39/100, Loss: 4.054126262664795\n",
      "Epoch 40/100, Loss: 1.7195253372192383\n",
      "Epoch 41/100, Loss: 1.0422186851501465\n",
      "Epoch 42/100, Loss: 1.6906555891036987\n",
      "Epoch 43/100, Loss: 0.15922030806541443\n",
      "Epoch 44/100, Loss: 5.593623638153076\n",
      "Epoch 45/100, Loss: 1.582680583000183\n",
      "Epoch 46/100, Loss: 0.9598299264907837\n",
      "Epoch 47/100, Loss: 0.31074637174606323\n",
      "Epoch 48/100, Loss: 0.0011592814698815346\n",
      "Epoch 49/100, Loss: 0.20551159977912903\n",
      "Epoch 50/100, Loss: 0.75001060962677\n",
      "Epoch 51/100, Loss: 0.03657897189259529\n",
      "Epoch 52/100, Loss: 0.010185951367020607\n",
      "Epoch 53/100, Loss: 0.026281801983714104\n",
      "Epoch 54/100, Loss: 0.13807456195354462\n",
      "Epoch 55/100, Loss: 3.7000374794006348\n",
      "Epoch 56/100, Loss: 0.0007437750464305282\n",
      "Epoch 57/100, Loss: 0.004175516311079264\n",
      "Epoch 58/100, Loss: 0.00019465731747914106\n",
      "Epoch 59/100, Loss: 0.08970046043395996\n",
      "Epoch 60/100, Loss: 0.00040249168523587286\n",
      "Epoch 61/100, Loss: 0.19197510182857513\n",
      "Epoch 62/100, Loss: 1.7881264284369536e-05\n",
      "Epoch 63/100, Loss: 0.2931840121746063\n",
      "Epoch 64/100, Loss: 0.10741785913705826\n",
      "Epoch 65/100, Loss: 0.007583503611385822\n",
      "Epoch 66/100, Loss: 0.0013077100738883018\n",
      "Epoch 67/100, Loss: 0.010183710604906082\n",
      "Epoch 68/100, Loss: 2.3761894702911377\n",
      "Epoch 69/100, Loss: 0.000314686301862821\n",
      "Epoch 70/100, Loss: 0.02268105559051037\n",
      "Epoch 71/100, Loss: 0.004212380852550268\n",
      "Epoch 72/100, Loss: 0.001486394670791924\n",
      "Epoch 73/100, Loss: 0.005090207792818546\n",
      "Epoch 74/100, Loss: 0.004313450772315264\n",
      "Epoch 75/100, Loss: 0.010044459253549576\n",
      "Epoch 76/100, Loss: 0.06771782785654068\n",
      "Epoch 77/100, Loss: 0.31625980138778687\n",
      "Epoch 78/100, Loss: 0.00029416647157631814\n",
      "Epoch 79/100, Loss: 0.013215354643762112\n",
      "Epoch 80/100, Loss: 1.0496888160705566\n",
      "Epoch 81/100, Loss: 0.8581784963607788\n",
      "Epoch 82/100, Loss: 0.4786387085914612\n",
      "Epoch 83/100, Loss: 0.0007509351125918329\n",
      "Epoch 84/100, Loss: 0.0036457993555814028\n",
      "Epoch 85/100, Loss: 0.12034433335065842\n",
      "Epoch 86/100, Loss: 0.2276456654071808\n",
      "Epoch 87/100, Loss: 0.24111540615558624\n",
      "Epoch 88/100, Loss: 0.0006768959574401379\n",
      "Epoch 89/100, Loss: 0.7814406156539917\n",
      "Epoch 90/100, Loss: 6.639736966462806e-05\n",
      "Epoch 91/100, Loss: 0.004914719145745039\n",
      "Epoch 92/100, Loss: 0.020420396700501442\n",
      "Epoch 93/100, Loss: 0.0017242372268810868\n",
      "Epoch 94/100, Loss: 5.517332553863525\n",
      "Epoch 95/100, Loss: 0.00042846560245379806\n",
      "Epoch 96/100, Loss: 0.00010442219354445115\n",
      "Epoch 97/100, Loss: 0.015170729719102383\n",
      "Epoch 98/100, Loss: 0.0008294146973639727\n",
      "Epoch 99/100, Loss: 0.0027934599202126265\n",
      "Epoch 100/100, Loss: 0.6521652340888977\n"
     ]
    }
   ],
   "source": [
    "# Define special tokens\n",
    "word_to_index = {\"<SOS>\": 0, \"<EOS>\": 1, \"<PAD>\": 2}  \n",
    " \n",
    "\n",
    "# Function to tokenize a sentence and update mapping dynamically\n",
    "def tokenize(sentence, word_to_index):\n",
    "    tokens = []\n",
    "    for word in sentence.lower().split():\n",
    "        if word not in word_to_index:\n",
    "            word_to_index[word] = len(word_to_index)  # Assign index to new words\n",
    "        tokens.append(word_to_index[word])\n",
    "    return tokens\n",
    "\n",
    "# Load dataset from CSV\n",
    "def load_sequences_from_csv(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    return df[\"Problem\"].tolist(), df[\"Solution\"].tolist()\n",
    "\n",
    "csv_file = \"simple_math_problems.csv\"\n",
    "input_sentences, target_sentences = load_sequences_from_csv(csv_file)\n",
    "\n",
    "# Tokenize input and target sentences\n",
    "input_data = [tokenize(sentence, word_to_index) for sentence in input_sentences]\n",
    "target_data = [[word_to_index[\"<SOS>\"]] + tokenize(sentence, word_to_index) + [word_to_index[\"<EOS>\"]]\n",
    "               for sentence in target_sentences]\n",
    "\n",
    "index_to_word = {v: k for k, v in word_to_index.items()}\n",
    "\n",
    "# Convert tokenized sentences into tensors\n",
    "input_tensors = [torch.tensor(seq) for seq in input_data]\n",
    "target_tensors = [torch.tensor(seq) for seq in target_data]\n",
    "\n",
    "# Apply dynamic padding\n",
    "input_padded = pad_sequence(input_tensors, batch_first=True, padding_value=word_to_index[\"<PAD>\"])\n",
    "target_padded = pad_sequence(target_tensors, batch_first=True, padding_value=word_to_index[\"<PAD>\"])\n",
    "\n",
    "class MathWordProblemDataset(Dataset):\n",
    "    def __init__(self, input_padded, target_padded):\n",
    "        self.input_data = input_padded\n",
    "        self.target_data = target_padded\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_data[idx], self.target_data[idx]\n",
    "\n",
    "dataset = MathWordProblemDataset(input_padded, target_padded)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_size = len(word_to_index)  # Vocabulary size\n",
    "output_size = len(word_to_index)\n",
    "hidden_size = 128\n",
    "\n",
    "encoder = Encoder(input_size, hidden_size).to(device)\n",
    "decoder = Decoder(output_size, hidden_size).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word_to_index[\"<PAD>\"])\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for input_seq, target_seq in dataloader:\n",
    "        input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, (hidden, cell) = encoder(input_seq)\n",
    "\n",
    "        decoder_input = torch.tensor([word_to_index[\"<SOS>\"]] * input_seq.size(0), device=device)\n",
    "        decoder_hidden, decoder_cell = hidden, cell\n",
    "\n",
    "        target_lengths = (target_seq != word_to_index[\"<PAD>\"]).sum(dim=1)\n",
    "\n",
    "        loss = 0\n",
    "        max_target_length = target_lengths.max().item()\n",
    "\n",
    "        for t in range(max_target_length):\n",
    "            still_active = t < target_lengths\n",
    "            if not still_active.any():\n",
    "                break\n",
    "\n",
    "            output, decoder_hidden, decoder_cell, _ = decoder(\n",
    "                decoder_input, decoder_hidden, decoder_cell, encoder_outputs\n",
    "            )\n",
    "            loss += (criterion(output, target_seq[:, t]) * still_active.float()).sum() / still_active.sum()\n",
    "\n",
    "            decoder_input = target_seq[:, t]  # Teacher forcing\n",
    "\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "torch.save(encoder.state_dict(), \"encoder-dynamic.pth\")\n",
    "torch.save(decoder.state_dict(), \"decoder-dynamic.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the son bitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<SOS>': 0, '<EOS>': 1, '<PAD>': 2, 'seventeen': 3, 'times': 4, 'one': 5, 'hundred': 6, 'twenty': 7, 'plus': 8, 'minus': 9, 'ninety': 10, 'two': 11, 'six': 12, 'divided': 13, 'by': 14, 'sixty': 15, 'nine': 16, 'three': 17, 'forty': 18, 'seven': 19, 'five': 20, 'thirty': 21, 'seventy': 22, 'eighty': 23, 'fourteen': 24, 'fifty': 25, 'sixteen': 26, 'four': 27, 'eight': 28, 'ten': 29, 'thirteen': 30, 'eighteen': 31, 'twelve': 32, 'fifteen': 33, 'nineteen': 34, 'eleven': 35, 'thousand': 36, 'zero': 37, 'point': 38, 'and': 39}\n",
      "[32, 9, 24]\n",
      "[0, 35]\n",
      "Output Sentence: <SOS> eleven\n"
     ]
    }
   ],
   "source": [
    "# load the trained model\n",
    "input_size = len(word_to_index)  # Same as during training\n",
    "output_size = len(word_to_index)\n",
    "hidden_size = 128  # Same as during training\n",
    "\n",
    "encoder = Encoder(input_size, hidden_size)\n",
    "decoder = Decoder(output_size, hidden_size)\n",
    "\n",
    "# Load the trained weights\n",
    "encoder.load_state_dict(torch.load(\"encoder-dynamic.pth\"))\n",
    "decoder.load_state_dict(torch.load(\"decoder-dynamic.pth\"))\n",
    "\n",
    "# Set the models to evaluation mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Tokenize the input sentence\n",
    "new_input_sentence = \"twelve minus fourteen\" #zero point eight six\n",
    "input_tokens = [word_to_index[word] for word in new_input_sentence.split()]\n",
    "input_seq = torch.tensor(input_tokens, dtype=torch.long).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "\n",
    "# generate the output sequence\n",
    "# Forward pass through the encoder\n",
    "encoder_outputs, (hidden, cell) = encoder(input_seq)\n",
    "\n",
    "# Initialize the decoder\n",
    "decoder_input = torch.tensor([word_to_index[\"<SOS>\"]], dtype=torch.long)  # Start-of-Sequence token\n",
    "decoder_hidden = hidden\n",
    "decoder_cell = cell\n",
    "\n",
    "# Generate output sequence\n",
    "output_sequence = []\n",
    "target_length = 100  # Maximum output sequence length\n",
    "\n",
    "for _ in range(target_length):\n",
    "    output, decoder_hidden, decoder_cell, _ = decoder(\n",
    "        decoder_input, decoder_hidden, decoder_cell, encoder_outputs\n",
    "    )\n",
    "    predicted_token = output.argmax(1).item()  # Get token with the highest probability\n",
    "    if predicted_token == word_to_index[\"<EOS>\"]:  # Stop at End-of-Sequence token\n",
    "        break\n",
    "    output_sequence.append(predicted_token)\n",
    "    decoder_input = torch.tensor([predicted_token], dtype=torch.long)\n",
    "\n",
    "print(word_to_index)\n",
    "\n",
    "print(input_tokens)\n",
    "\n",
    "print(output_sequence)\n",
    "\n",
    "\n",
    "# Convert tokens back to words\n",
    "output_sentence = \" \".join([index_to_word[token] for token in output_sequence])\n",
    "print(\"Output Sentence:\", output_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
