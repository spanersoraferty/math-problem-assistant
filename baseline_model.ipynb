{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        embedded = self.embedding(input_seq)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        return outputs, (hidden, cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        seq_len = encoder_outputs.size(1)\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, seq_len, 1)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        energy = energy.permute(0, 2, 1)\n",
    "        v = self.v.repeat(encoder_outputs.size(0), 1).unsqueeze(1)\n",
    "        attention_weights = torch.bmm(v, energy).squeeze(1)\n",
    "        return torch.softmax(attention_weights, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "        self.attention = Attention(hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden, cell, encoder_outputs):\n",
    "        input = input.unsqueeze(1)\n",
    "        embedded = self.embedding(input)\n",
    "        lstm_output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        attention_weights = self.attention(hidden[-1], encoder_outputs)\n",
    "        context = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs)\n",
    "        lstm_output = lstm_output.squeeze(1)\n",
    "        context = context.squeeze(1)\n",
    "        output = self.fc(torch.cat((lstm_output, context), dim=1))\n",
    "        return output, hidden, cell, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and Vocabulary Setup\n",
    "First, create a vocabulary and tokenize the input sentence (e.g., \"two plus four\" etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and vocab setup\n",
    "# Create a vocabulary mapping words to indices\n",
    "word_to_index = {\"<SOS>\": 0, \"<EOS>\": 1, \"<PAD>\": 2, \"two\": 3, \"plus\": 4, \"four\": 5, \"equals\": 6, \"six\": 7, \"three\": 8, \"minus\": 9, \"one\": 10}\n",
    "index_to_word = {v: k for k, v in word_to_index.items()}  # Reverse mapping for decoding\n",
    "\n",
    "# Example input and target sequences\n",
    "input_sentence = \"two plus four\"\n",
    "target_sentence = \"equals six\"\n",
    "\n",
    "# Tokenize the sentences\n",
    "input_tokens = [word_to_index[word] for word in input_sentence.split()]\n",
    "target_tokens = [word_to_index[\"<SOS>\"]] + [word_to_index[word] for word in target_sentence.split()] + [word_to_index[\"<EOS>\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the math problem dataset from the tokenzied data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathWordProblemDataset(Dataset):\n",
    "    def __init__(self, input_sentences, target_sentences, word_to_index):\n",
    "        self.input_data = [[word_to_index[word] for word in sentence.split()] for sentence in input_sentences]\n",
    "        self.target_data = [[word_to_index[\"<SOS>\"]] + [word_to_index[word] for word in sentence.split()] + [word_to_index[\"<EOS>\"]] for sentence in target_sentences]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.input_data[idx], dtype=torch.long), torch.tensor(self.target_data[idx], dtype=torch.long)\n",
    "\n",
    "# Example data\n",
    "input_sentences = [\"two plus four\"]\n",
    "target_sentences = [\"equals six\"]\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = MathWordProblemDataset(input_sentences, target_sentences, word_to_index)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "target_length = len(target_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 2.3638370037078857\n",
      "Epoch 2/100, Loss: 2.1916778087615967\n",
      "Epoch 3/100, Loss: 2.0262343883514404\n",
      "Epoch 4/100, Loss: 1.8628535270690918\n",
      "Epoch 5/100, Loss: 1.7023825645446777\n",
      "Epoch 6/100, Loss: 1.5464227199554443\n",
      "Epoch 7/100, Loss: 1.396775722503662\n",
      "Epoch 8/100, Loss: 1.2553573846817017\n",
      "Epoch 9/100, Loss: 1.1237825155258179\n",
      "Epoch 10/100, Loss: 1.0029860734939575\n",
      "Epoch 11/100, Loss: 0.8931413888931274\n",
      "Epoch 12/100, Loss: 0.7939382791519165\n",
      "Epoch 13/100, Loss: 0.7049980163574219\n",
      "Epoch 14/100, Loss: 0.6261006593704224\n",
      "Epoch 15/100, Loss: 0.5570806264877319\n",
      "Epoch 16/100, Loss: 0.4974972605705261\n",
      "Epoch 17/100, Loss: 0.44633978605270386\n",
      "Epoch 18/100, Loss: 0.40208011865615845\n",
      "Epoch 19/100, Loss: 0.36314263939857483\n",
      "Epoch 20/100, Loss: 0.3284223973751068\n",
      "Epoch 21/100, Loss: 0.29739901423454285\n",
      "Epoch 22/100, Loss: 0.2698220908641815\n",
      "Epoch 23/100, Loss: 0.2453511357307434\n",
      "Epoch 24/100, Loss: 0.223469540476799\n",
      "Epoch 25/100, Loss: 0.20362097024917603\n",
      "Epoch 26/100, Loss: 0.18538545072078705\n",
      "Epoch 27/100, Loss: 0.16856442391872406\n",
      "Epoch 28/100, Loss: 0.153138667345047\n",
      "Epoch 29/100, Loss: 0.13915926218032837\n",
      "Epoch 30/100, Loss: 0.12662331759929657\n",
      "Epoch 31/100, Loss: 0.11540412902832031\n",
      "Epoch 32/100, Loss: 0.1053258404135704\n",
      "Epoch 33/100, Loss: 0.0962606817483902\n",
      "Epoch 34/100, Loss: 0.08812098950147629\n",
      "Epoch 35/100, Loss: 0.08081012964248657\n",
      "Epoch 36/100, Loss: 0.07421035319566727\n",
      "Epoch 37/100, Loss: 0.06820814311504364\n",
      "Epoch 38/100, Loss: 0.06271903961896896\n",
      "Epoch 39/100, Loss: 0.05769369378685951\n",
      "Epoch 40/100, Loss: 0.053105492144823074\n",
      "Epoch 41/100, Loss: 0.048938456922769547\n",
      "Epoch 42/100, Loss: 0.045179374516010284\n",
      "Epoch 43/100, Loss: 0.04181207716464996\n",
      "Epoch 44/100, Loss: 0.03880901634693146\n",
      "Epoch 45/100, Loss: 0.036130353808403015\n",
      "Epoch 46/100, Loss: 0.03373386710882187\n",
      "Epoch 47/100, Loss: 0.03158160299062729\n",
      "Epoch 48/100, Loss: 0.029642876237630844\n",
      "Epoch 49/100, Loss: 0.02789194881916046\n",
      "Epoch 50/100, Loss: 0.02630672976374626\n",
      "Epoch 51/100, Loss: 0.024867678061127663\n",
      "Epoch 52/100, Loss: 0.02355741336941719\n",
      "Epoch 53/100, Loss: 0.02236100286245346\n",
      "Epoch 54/100, Loss: 0.021265819668769836\n",
      "Epoch 55/100, Loss: 0.020260529592633247\n",
      "Epoch 56/100, Loss: 0.019336212426424026\n",
      "Epoch 57/100, Loss: 0.018484804779291153\n",
      "Epoch 58/100, Loss: 0.017699141055345535\n",
      "Epoch 59/100, Loss: 0.016973378136754036\n",
      "Epoch 60/100, Loss: 0.016301767900586128\n",
      "Epoch 61/100, Loss: 0.015679555013775826\n",
      "Epoch 62/100, Loss: 0.015102122910320759\n",
      "Epoch 63/100, Loss: 0.014565570279955864\n",
      "Epoch 64/100, Loss: 0.014066088013350964\n",
      "Epoch 65/100, Loss: 0.013600140810012817\n",
      "Epoch 66/100, Loss: 0.013165065087378025\n",
      "Epoch 67/100, Loss: 0.012757827527821064\n",
      "Epoch 68/100, Loss: 0.012376360595226288\n",
      "Epoch 69/100, Loss: 0.012018022127449512\n",
      "Epoch 70/100, Loss: 0.011681083589792252\n",
      "Epoch 71/100, Loss: 0.011363629251718521\n",
      "Epoch 72/100, Loss: 0.011063974350690842\n",
      "Epoch 73/100, Loss: 0.010780786164104939\n",
      "Epoch 74/100, Loss: 0.010512638837099075\n",
      "Epoch 75/100, Loss: 0.01025833934545517\n",
      "Epoch 76/100, Loss: 0.01001669280230999\n",
      "Epoch 77/100, Loss: 0.009786796756088734\n",
      "Epoch 78/100, Loss: 0.009567894041538239\n",
      "Epoch 79/100, Loss: 0.009358844719827175\n",
      "Epoch 80/100, Loss: 0.009159273467957973\n",
      "Epoch 81/100, Loss: 0.008968211710453033\n",
      "Epoch 82/100, Loss: 0.008785193786025047\n",
      "Epoch 83/100, Loss: 0.008609841577708721\n",
      "Epoch 84/100, Loss: 0.008441304787993431\n",
      "Epoch 85/100, Loss: 0.00827926117926836\n",
      "Epoch 86/100, Loss: 0.008123478852212429\n",
      "Epoch 87/100, Loss: 0.00797325186431408\n",
      "Epoch 88/100, Loss: 0.007828496396541595\n",
      "Epoch 89/100, Loss: 0.0076889777556061745\n",
      "Epoch 90/100, Loss: 0.007554107345640659\n",
      "Epoch 91/100, Loss: 0.0074237678200006485\n",
      "Epoch 92/100, Loss: 0.007297697477042675\n",
      "Epoch 93/100, Loss: 0.007175719831138849\n",
      "Epoch 94/100, Loss: 0.007057451643049717\n",
      "Epoch 95/100, Loss: 0.006943072658032179\n",
      "Epoch 96/100, Loss: 0.0068319328129291534\n",
      "Epoch 97/100, Loss: 0.006724211387336254\n",
      "Epoch 98/100, Loss: 0.006619494874030352\n",
      "Epoch 99/100, Loss: 0.0065179322846233845\n",
      "Epoch 100/100, Loss: 0.006419200450181961\n"
     ]
    }
   ],
   "source": [
    "# Define the device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instantiate the encoder and decoder\n",
    "input_size = len(word_to_index)  # Total vocabulary size\n",
    "output_size = len(word_to_index)  # Vocabulary size\n",
    "hidden_size = 128\n",
    "encoder = Encoder(input_size, hidden_size).to(device)\n",
    "decoder = Decoder(output_size, hidden_size).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word_to_index[\"<PAD>\"])  # Ignore padding tokens\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100  # Define the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    for input_seq, target_seq in dataloader:\n",
    "        # Move data to device (CPU or GPU)\n",
    "        input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        # Encoder forward pass\n",
    "        encoder_outputs, (hidden, cell) = encoder(input_seq)\n",
    "\n",
    "        # Decoder initialization\n",
    "        decoder_input = torch.tensor([word_to_index[\"<SOS>\"]]*input_seq.size(0), device=device)\n",
    "        decoder_hidden, decoder_cell = hidden, cell\n",
    "\n",
    "        # Iterate over the target sequence\n",
    "        loss = 0\n",
    "        for t in range(target_seq.size(1)):\n",
    "            output, decoder_hidden, decoder_cell, attention_weights = decoder(\n",
    "                decoder_input, decoder_hidden, decoder_cell, encoder_outputs\n",
    "            )\n",
    "            loss += criterion(output, target_seq[:, t])\n",
    "            decoder_input = target_seq[:, t]  # Teacher forcing\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item() / target_seq.size(1)}\")\n",
    "\n",
    "\n",
    "torch.save(encoder.state_dict(), \"encoder.pth\")\n",
    "torch.save(decoder.state_dict(), \"decoder.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Sentence: <SOS> equals six\n"
     ]
    }
   ],
   "source": [
    "# load the trained model\n",
    "input_size = len(word_to_index)  # Same as during training\n",
    "output_size = len(word_to_index)\n",
    "hidden_size = 128  # Same as during training\n",
    "\n",
    "encoder = Encoder(input_size, hidden_size)\n",
    "decoder = Decoder(output_size, hidden_size)\n",
    "\n",
    "# Load the trained weights\n",
    "encoder.load_state_dict(torch.load(\"encoder.pth\"))\n",
    "decoder.load_state_dict(torch.load(\"decoder.pth\"))\n",
    "\n",
    "# Set the models to evaluation mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Tokenize the input sentence\n",
    "new_input_sentence = \"two plus four\"\n",
    "input_tokens = [word_to_index[word] for word in new_input_sentence.split()]\n",
    "input_seq = torch.tensor(input_tokens, dtype=torch.long).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# generate the output sequence\n",
    "# Forward pass through the encoder\n",
    "encoder_outputs, (hidden, cell) = encoder(input_seq)\n",
    "\n",
    "# Initialize the decoder\n",
    "decoder_input = torch.tensor([word_to_index[\"<SOS>\"]], dtype=torch.long)  # Start-of-Sequence token\n",
    "decoder_hidden = hidden\n",
    "decoder_cell = cell\n",
    "\n",
    "# Generate output sequence\n",
    "output_sequence = []\n",
    "target_length = 10  # Maximum output sequence length\n",
    "\n",
    "for _ in range(target_length):\n",
    "    output, decoder_hidden, decoder_cell, _ = decoder(\n",
    "        decoder_input, decoder_hidden, decoder_cell, encoder_outputs\n",
    "    )\n",
    "    predicted_token = output.argmax(1).item()  # Get token with the highest probability\n",
    "    if predicted_token == word_to_index[\"<EOS>\"]:  # Stop at End-of-Sequence token\n",
    "        break\n",
    "    output_sequence.append(predicted_token)\n",
    "    decoder_input = torch.tensor([predicted_token], dtype=torch.long)\n",
    "\n",
    "# Convert tokens back to words\n",
    "output_sentence = \" \".join([index_to_word[token] for token in output_sequence])\n",
    "print(\"Output Sentence:\", output_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build with padding for variable lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 8.916961669921875\n",
      "Epoch 2/100, Loss: 2.8817436695098877\n",
      "Epoch 3/100, Loss: 1.964099407196045\n",
      "Epoch 4/100, Loss: 1.2228384017944336\n",
      "Epoch 5/100, Loss: 3.6843483448028564\n",
      "Epoch 6/100, Loss: 0.7471533417701721\n",
      "Epoch 7/100, Loss: 1.1379590034484863\n",
      "Epoch 8/100, Loss: 0.6730915307998657\n",
      "Epoch 9/100, Loss: 4.693273067474365\n",
      "Epoch 10/100, Loss: 3.0276174545288086\n",
      "Epoch 11/100, Loss: 3.100637435913086\n",
      "Epoch 12/100, Loss: 2.5766429901123047\n",
      "Epoch 13/100, Loss: 0.18210314214229584\n",
      "Epoch 14/100, Loss: 0.49282106757164\n",
      "Epoch 15/100, Loss: 0.09156893938779831\n",
      "Epoch 16/100, Loss: 0.12635834515094757\n",
      "Epoch 17/100, Loss: 0.19743449985980988\n",
      "Epoch 18/100, Loss: 2.0919671058654785\n",
      "Epoch 19/100, Loss: 3.574359178543091\n",
      "Epoch 20/100, Loss: 0.22900785505771637\n",
      "Epoch 21/100, Loss: 2.920043468475342\n",
      "Epoch 22/100, Loss: 0.3592512309551239\n",
      "Epoch 23/100, Loss: 0.04478819668292999\n",
      "Epoch 24/100, Loss: 0.041424792259931564\n",
      "Epoch 25/100, Loss: 0.11192981153726578\n",
      "Epoch 26/100, Loss: 1.6294223070144653\n",
      "Epoch 27/100, Loss: 0.008475856855511665\n",
      "Epoch 28/100, Loss: 0.09934533387422562\n",
      "Epoch 29/100, Loss: 2.2882978916168213\n",
      "Epoch 30/100, Loss: 0.0011446501594036818\n",
      "Epoch 31/100, Loss: 0.029624873772263527\n",
      "Epoch 32/100, Loss: 0.02152932435274124\n",
      "Epoch 33/100, Loss: 0.38362449407577515\n",
      "Epoch 34/100, Loss: 2.0995090007781982\n",
      "Epoch 35/100, Loss: 1.4290659427642822\n",
      "Epoch 36/100, Loss: 2.871495485305786\n",
      "Epoch 37/100, Loss: 1.00838303565979\n",
      "Epoch 38/100, Loss: 0.698391854763031\n",
      "Epoch 39/100, Loss: 0.10427127778530121\n",
      "Epoch 40/100, Loss: 0.02055458165705204\n",
      "Epoch 41/100, Loss: 1.496626853942871\n",
      "Epoch 42/100, Loss: 0.4078481197357178\n",
      "Epoch 43/100, Loss: 0.13992774486541748\n",
      "Epoch 44/100, Loss: 0.06903468817472458\n",
      "Epoch 45/100, Loss: 0.0036130172666162252\n",
      "Epoch 46/100, Loss: 0.01309241633862257\n",
      "Epoch 47/100, Loss: 0.0013168039731681347\n",
      "Epoch 48/100, Loss: 0.0005986486794427037\n",
      "Epoch 49/100, Loss: 2.2992007732391357\n",
      "Epoch 50/100, Loss: 0.004897069651633501\n",
      "Epoch 51/100, Loss: 0.00048175122356042266\n",
      "Epoch 52/100, Loss: 0.30448395013809204\n",
      "Epoch 53/100, Loss: 1.9087576866149902\n",
      "Epoch 54/100, Loss: 0.004052286967635155\n",
      "Epoch 55/100, Loss: 0.6643252372741699\n",
      "Epoch 56/100, Loss: 0.0025310025084763765\n",
      "Epoch 57/100, Loss: 0.01222306303679943\n",
      "Epoch 58/100, Loss: 0.0193979162722826\n",
      "Epoch 59/100, Loss: 0.040457505732774734\n",
      "Epoch 60/100, Loss: 0.0037154818419367075\n",
      "Epoch 61/100, Loss: 1.912156105041504\n",
      "Epoch 62/100, Loss: 0.0598052479326725\n",
      "Epoch 63/100, Loss: 0.023326998576521873\n",
      "Epoch 64/100, Loss: 0.00040920250467024744\n",
      "Epoch 65/100, Loss: 0.03740016371011734\n",
      "Epoch 66/100, Loss: 0.019608264788985252\n",
      "Epoch 67/100, Loss: 0.00011991834617219865\n",
      "Epoch 68/100, Loss: 0.8097666501998901\n",
      "Epoch 69/100, Loss: 0.0005627787322737277\n",
      "Epoch 70/100, Loss: 0.08048399537801743\n",
      "Epoch 71/100, Loss: 0.18638494610786438\n",
      "Epoch 72/100, Loss: 3.1715710163116455\n",
      "Epoch 73/100, Loss: 0.8819248080253601\n",
      "Epoch 74/100, Loss: 0.10064884275197983\n",
      "Epoch 75/100, Loss: 0.10740570724010468\n",
      "Epoch 76/100, Loss: 7.712648948654532e-05\n",
      "Epoch 77/100, Loss: 0.21291053295135498\n",
      "Epoch 78/100, Loss: 0.011200947687029839\n",
      "Epoch 79/100, Loss: 0.0025787455961108208\n",
      "Epoch 80/100, Loss: 0.7824549078941345\n",
      "Epoch 81/100, Loss: 0.013911345042288303\n",
      "Epoch 82/100, Loss: 0.00025747346808202565\n",
      "Epoch 83/100, Loss: 3.291053533554077\n",
      "Epoch 84/100, Loss: 0.11505304276943207\n",
      "Epoch 85/100, Loss: 0.0009222552762366831\n",
      "Epoch 86/100, Loss: 0.004306951072067022\n",
      "Epoch 87/100, Loss: 0.20542557537555695\n",
      "Epoch 88/100, Loss: 0.011001156643033028\n",
      "Epoch 89/100, Loss: 0.11449958384037018\n",
      "Epoch 90/100, Loss: 0.005045238882303238\n",
      "Epoch 91/100, Loss: 0.48614269495010376\n",
      "Epoch 92/100, Loss: 0.21228304505348206\n",
      "Epoch 93/100, Loss: 0.01605677604675293\n",
      "Epoch 94/100, Loss: 0.0017886845162138343\n",
      "Epoch 95/100, Loss: 0.1120411679148674\n",
      "Epoch 96/100, Loss: 0.0010947557166218758\n",
      "Epoch 97/100, Loss: 0.22619672119617462\n",
      "Epoch 98/100, Loss: 0.0032158815301954746\n",
      "Epoch 99/100, Loss: 0.3075896203517914\n",
      "Epoch 100/100, Loss: 0.015552577562630177\n"
     ]
    }
   ],
   "source": [
    "# Define special tokens\n",
    "word_to_index = {\"<SOS>\": 0, \"<EOS>\": 1, \"<PAD>\": 2}  \n",
    " \n",
    "\n",
    "# Function to tokenize a sentence and update mapping dynamically\n",
    "def tokenize(sentence, word_to_index):\n",
    "    tokens = []\n",
    "    for word in sentence.lower().split():\n",
    "        if word not in word_to_index:\n",
    "            word_to_index[word] = len(word_to_index)  # Assign index to new words\n",
    "        tokens.append(word_to_index[word])\n",
    "    return tokens\n",
    "\n",
    "# Load dataset from CSV\n",
    "def load_sequences_from_csv(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    return df[\"Problem\"].tolist(), df[\"Solution\"].tolist()\n",
    "\n",
    "csv_file = \"simple_math_problems.csv\"\n",
    "input_sentences, target_sentences = load_sequences_from_csv(csv_file)\n",
    "\n",
    "# Tokenize input and target sentences\n",
    "input_data = [tokenize(sentence, word_to_index) for sentence in input_sentences]\n",
    "target_data = [[word_to_index[\"<SOS>\"]] + tokenize(sentence, word_to_index) + [word_to_index[\"<EOS>\"]]\n",
    "               for sentence in target_sentences]\n",
    "\n",
    "index_to_word = {v: k for k, v in word_to_index.items()}\n",
    "\n",
    "# Convert tokenized sentences into tensors\n",
    "input_tensors = [torch.tensor(seq) for seq in input_data]\n",
    "target_tensors = [torch.tensor(seq) for seq in target_data]\n",
    "\n",
    "# Apply dynamic padding\n",
    "input_padded = pad_sequence(input_tensors, batch_first=True, padding_value=word_to_index[\"<PAD>\"])\n",
    "target_padded = pad_sequence(target_tensors, batch_first=True, padding_value=word_to_index[\"<PAD>\"])\n",
    "\n",
    "class MathWordProblemDataset(Dataset):\n",
    "    def __init__(self, input_padded, target_padded):\n",
    "        self.input_data = input_padded\n",
    "        self.target_data = target_padded\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_data[idx], self.target_data[idx]\n",
    "\n",
    "dataset = MathWordProblemDataset(input_padded, target_padded)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_size = len(word_to_index)  # Vocabulary size\n",
    "output_size = len(word_to_index)\n",
    "hidden_size = 128\n",
    "\n",
    "encoder = Encoder(input_size, hidden_size).to(device)\n",
    "decoder = Decoder(output_size, hidden_size).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word_to_index[\"<PAD>\"])\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for input_seq, target_seq in dataloader:\n",
    "        input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, (hidden, cell) = encoder(input_seq)\n",
    "\n",
    "        decoder_input = torch.tensor([word_to_index[\"<SOS>\"]] * input_seq.size(0), device=device)\n",
    "        decoder_hidden, decoder_cell = hidden, cell\n",
    "\n",
    "        target_lengths = (target_seq != word_to_index[\"<PAD>\"]).sum(dim=1)\n",
    "\n",
    "        loss = 0\n",
    "        max_target_length = target_lengths.max().item()\n",
    "\n",
    "        for t in range(max_target_length):\n",
    "            still_active = t < target_lengths\n",
    "            if not still_active.any():\n",
    "                break\n",
    "\n",
    "            output, decoder_hidden, decoder_cell, _ = decoder(\n",
    "                decoder_input, decoder_hidden, decoder_cell, encoder_outputs\n",
    "            )\n",
    "            loss += (criterion(output, target_seq[:, t]) * still_active.float()).sum() / still_active.sum()\n",
    "\n",
    "            decoder_input = target_seq[:, t]  # Teacher forcing\n",
    "\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "torch.save(encoder.state_dict(), \"encoder-dynamic.pth\")\n",
    "torch.save(decoder.state_dict(), \"decoder-dynamic.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the son bitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_to_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# load the trained model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m input_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(word_to_index)  \u001b[38;5;66;03m# Same as during training\u001b[39;00m\n\u001b[0;32m      3\u001b[0m output_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(word_to_index)\n\u001b[0;32m      4\u001b[0m hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m  \u001b[38;5;66;03m# Same as during training\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word_to_index' is not defined"
     ]
    }
   ],
   "source": [
    "# load the trained model\n",
    "input_size = len(word_to_index)  # Same as during training\n",
    "output_size = len(word_to_index)\n",
    "hidden_size = 128  # Same as during training\n",
    "\n",
    "encoder = Encoder(input_size, hidden_size)\n",
    "decoder = Decoder(output_size, hidden_size)\n",
    "\n",
    "# Load the trained weights\n",
    "encoder.load_state_dict(torch.load(\"encoder-dynamic.pth\"))\n",
    "decoder.load_state_dict(torch.load(\"decoder-dynamic.pth\"))\n",
    "\n",
    "# Set the models to evaluation mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Tokenize the input sentence\n",
    "new_input_sentence = \"twelve minus fourteen\" #zero point eight six\n",
    "input_tokens = [word_to_index[word] for word in new_input_sentence.split()]\n",
    "input_seq = torch.tensor(input_tokens, dtype=torch.long).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "\n",
    "# generate the output sequence\n",
    "# Forward pass through the encoder\n",
    "encoder_outputs, (hidden, cell) = encoder(input_seq)\n",
    "\n",
    "# Initialize the decoder\n",
    "decoder_input = torch.tensor([word_to_index[\"<SOS>\"]], dtype=torch.long)  # Start-of-Sequence token\n",
    "decoder_hidden = hidden\n",
    "decoder_cell = cell\n",
    "\n",
    "# Generate output sequence\n",
    "output_sequence = []\n",
    "target_length = 100  # Maximum output sequence length\n",
    "\n",
    "for _ in range(target_length):\n",
    "    output, decoder_hidden, decoder_cell, _ = decoder(\n",
    "        decoder_input, decoder_hidden, decoder_cell, encoder_outputs\n",
    "    )\n",
    "    predicted_token = output.argmax(1).item()  # Get token with the highest probability\n",
    "    if predicted_token == word_to_index[\"<EOS>\"]:  # Stop at End-of-Sequence token\n",
    "        break\n",
    "    output_sequence.append(predicted_token)\n",
    "    decoder_input = torch.tensor([predicted_token], dtype=torch.long)\n",
    "\n",
    "print(word_to_index)\n",
    "\n",
    "print(input_tokens)\n",
    "\n",
    "print(output_sequence)\n",
    "\n",
    "\n",
    "# Convert tokens back to words\n",
    "output_sentence = \" \".join([index_to_word[token] for token in output_sequence])\n",
    "print(\"Output Sentence:\", output_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
